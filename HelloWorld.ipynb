{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:14.172000",
     "start_time": "2016-06-29T15:00:13.482000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateBreedFeatures(data):\n",
    "    l1=['American Hairless Terrier','American Leopard Hound','Appenzeller Sennenhunde','Azawakh','Barbet',\n",
    "        'Basset Fauve de Bretagne','Belgian Laekenois','Biewer Terrier','Bolognese','Bracco Italiano',\n",
    "        'Braque du Bourbonnais','Broholmer','Catahoula Leopard Dog','Caucasian Ovcharka','Central Asian Shepherd Dog',\n",
    "        'Czechoslovakian Vlcak','Danish-Swedish Farmdog','Deutscher Wachtelhund','Dogo Argentino',\n",
    "        'Drentsche Patrijshond','Drever','Dutch Shepherd','Estrela Mountain Dog','Eurasier','French Spaniel',\n",
    "        'German Longhaired Pointer','German Spitz','Grand Basset Griffon Vendeen','Hamiltonstovare','Hovawart',\n",
    "        'Jagdterrier','Jindo','Kai Ken','Karelian Bear Dog','Kishu Ken','Kromfohrlander','Lancashire Heeler',\n",
    "        'Mudi','Nederlandse Kooikerhondje','Norrbottenspets','Perro de Presa Canario','Peruvian Inca Orchid',\n",
    "        'Portuguese Podengo','Portuguese Pointer','Portuguese Sheepdog','Pumi','Pyrenean Mastiff',\n",
    "        'Rafeiro do Alentejo','Russian Toy','Russian Tsvetnaya Bolonka','Schapendoes','Shikoku',\n",
    "        'Slovensky Cuvac','Slovensky Kopov','Sloughi','Small Munsterlander Pointer','Spanish Mastiff',\n",
    "        'Stabyhoun','Swedish Lapphund','Thai Ridgeback','Tornjak','Tosa','Transylvanian Hound',\n",
    "        'Treeing Tennessee Brindle','Working Kelpie','Australian Cattle Dog','Australian Shepherd',\n",
    "        'Bearded Collie','Beauceron','Belgian Malinois','Belgian Sheepdog','Belgian Tervuren','Bergamasco',\n",
    "        'Berger Picard','Border Collie','Bouvier des Flandres','Briard','Canaan Dog','Cardigan Welsh Corgi',\n",
    "        'Collie','Entlebucher Mountain Dog','Finnish Lapphund','German Shepherd Dog','Icelandic Sheepdog',\n",
    "        'Miniature American Shepherd','Norwegian Buhund','Old English Sheepdog','Pembroke Welsh Corgi',\n",
    "        'Polish Lowland Sheepdog','Puli','Pyrenean Shepherd','Shetland Sheepdog','Spanish Water Dog',\n",
    "        'Swedish Vallhund','Afghan Hound','American English Coonhound','American Foxhound','Basenji',\n",
    "        'Basset Hound','Beagle','Black and Tan Coonhound','Bloodhound','Bluetick Coonhound','Borzoi',\n",
    "        'Cirneco de l etna','Dachshund','English Foxhound','Greyhound','Harrier','Ibizan Hound','Irish Wolfhound',\n",
    "        'Norwegian Elkhound','Otterhound','Petit Basset Griffon Vendeen','Pharaoh Hound','Plott',\n",
    "        'Portuguese Podengo Pequeno','Redbone Coonhound','Rhodesian Ridgeback','Saluki','Scottish Deerhound',\n",
    "        'Treeing Walker Coonhound','Whippet','American Eskimo Dog','Bichon Frise','Boston Terrier','Bulldog',\n",
    "        'Chinese Shar-Pei','Chow Chow','Coton de Tulear','Dalmatian','Finnish Spitz','French Bulldog','Keeshond',\n",
    "        'Lhasa Apso','Lowchen','Norwegian Lundehund','Poodle','Schipperke','Shiba Inu','Tibetan Spaniel',\n",
    "        'Tibetan Terrier','Xoloitzcuintli','American Water Spaniel','Boykin Spaniel','Brittany',\n",
    "        'Chesapeake Bay Retriever','Clumber Spaniel','Cocker Spaniel','Curly-Coated Retriever',\n",
    "        'English Cocker Spaniel','English Setter','English Springer Spaniel','Field Spaniel',\n",
    "        'Flat-Coated Retriever','German Shorthaired Pointer','German Wirehaired Pointer','Golden Retriever',\n",
    "        'Gordon Setter','Irish Red and White Setter','Irish Setter','Irish Water Spaniel','Labrador Retriever',\n",
    "        'Lagotto Romagnolo','Nova Scotia Duck Tolling Retriever','Pointer','Spinone Italiano','Sussex Spaniel',\n",
    "        'Vizsla','Weimaraner','Welsh Springer Spaniel','Wirehaired Pointing Griffon','Wirehaired Vizsla',\n",
    "        'Airedale Terrier','American Staffordshire Terrier','Australian Terrier','Bedlington Terrier',\n",
    "        'Border Terrier','Bull Terrier','Cairn Terrier','Cesky Terrier','Dandie Dinmont Terrier',\n",
    "        'Glen of Imaal Terrier','Irish Terrier','Kerry Blue Terrier','Lakeland Terrier','Manchester Terrier',\n",
    "        'Miniature Bull Terrier','Miniature Schnauzer','Norfolk Terrier','Norwich Terrier','Parson Russell Terrier',\n",
    "        'Rat Terrier','Russell Terrier','Scottish Terrier','Sealyham Terrier','Skye Terrier','Smooth Fox Terrier',\n",
    "        'Soft Coated Wheaten Terrier','Staffordshire Bull Terrier','Welsh Terrier','West Highland White Terrier',\n",
    "        'Wire Fox Terrier','Affenpinscher','Brussels Griffon','Cavalier King Charles Spaniel','Chihuahua',\n",
    "        'Chinese Crested','English Toy Spaniel','Havanese','Italian Greyhound','Japanese Chin','Maltese',\n",
    "        'Miniature Pinscher','Papillon','Pekingese','Pomeranian','Pug','Shih Tzu','Silky Terrier','Toy Fox Terrier',\n",
    "        'Yorkshire Terrier','Akita','Alaskan Malamute','Anatolian Shepherd Dog','Bernese Mountain Dog',\n",
    "        'Black Russian Terrier','Boerboel','Boxer','Bullmastiff','Cane Corso','Chinook','Doberman Pinscher',\n",
    "        'Dogue de Bordeaux','German Pinscher','Giant Schnauzer','Great Dane','Great Pyrenees',\n",
    "        'Greater Swiss Mountain Dog','Komondor','Kuvasz','Leonberger','Mastiff','Neapolitan Mastiff','Newfoundland',\n",
    "        'Portuguese Water Dog','Rottweiler','Samoyed','Siberian Husky','Standard Schnauzer','Tibetan Mastiff',\n",
    "        'St. Bernard']\n",
    "    l2=['FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS',\n",
    "        'FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS',\n",
    "        'FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS',\n",
    "        'FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','FSS','Herding','Herding','Herding','Herding',\n",
    "        'Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding',\n",
    "        'Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding','Herding',\n",
    "        'Herding','Herding','Herding','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound',\n",
    "        'Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound','Hound',\n",
    "        'Hound','Hound','Hound','Hound','Hound','Hound','Non_sporting','Non_sporting','Non_sporting','Non_sporting',\n",
    "        'Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting',\n",
    "        'Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting','Non_sporting',\n",
    "        'Non_sporting','Non_sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting',\n",
    "        'Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting',\n",
    "        'Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting','Sporting',\n",
    "        'Sporting','Sporting','Sporting','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier',\n",
    "        'Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier',\n",
    "        'Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier','Terrier',\n",
    "        'Terrier','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy','Toy',\n",
    "        'Toy','Toy','Toy','Working','Working','Working','Working','Working','Working','Working','Working','Working',\n",
    "        'Working','Working','Working','Working','Working','Working','Working','Working','Working','Working','Working',\n",
    "        'Working','Working','Working','Working','Working','Working','Working','Working','Working','Working']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['group']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    \n",
    "    l1=['Akita','Alaskan Malamute','Anatolian Shepherd Dog','Argentine Dogo','Beauceron','Bernese Mountain Dog',\n",
    "        'Black Russian Terrier','Bloodhound','Borzoi','Bouvier des Flandres','Briard','Bullmastiff','Cane Corso',\n",
    "        'Caucasian Ovcharka','Central Asian Shepherd Dog','Curly-Coated Retriever','Doberman Pinsch','Greyhound',\n",
    "        'Otterhounds','Spinone Italiano','Afghan Hound','Airedale Terrier','American Foxhound',\n",
    "        'American Staffordshire Terrier','Appenzeller Sennenhunde','Belgian Sheepdog','Belgian Tervuren',\n",
    "        'Bergamasco','Black and Tan Coonhound','Bluetick Coonhound','Boxer','Bracco Italiano','Catahoula Leopard',\n",
    "        'Chesapeake Bay Retriever','Chinook','Clumber Spaniel','English Setter','Flat Coat Retriever',\n",
    "        'German Shorthaired Pointer','German Wirehaired Pointer','Golden Retrievers','Gordon Setters',\n",
    "        'Irish Red and White Setters','Irish Setters','Labrador Retriever','The Standard Poodle','Redbone Coonhound',\n",
    "        'Thai Ridgeback','Weimaraner','American English Coonhound','Australian Shepherd','Azawakh','Basset Hound',\n",
    "        'Bearded Collie','Belgian Laekenois','Belgian Malinois','Bull Terrier','Bulldog','Chinese Sharpei',\n",
    "        'Chow Chow','Collie','Dalmatian','English Springer Spaniel','Entlebucher Mountain Dog','Field Spaniel',\n",
    "        'Finnish Lapphund','Grand Basset Griffon Vendéen','Harrier','Ibizan Hounds','Irish Water Spaniels',\n",
    "        'Keeshond','Norwegian Elkhound','Nova Scotia Duck Tolling Retriever','The Pharaoh Hound','The Plott',\n",
    "        'The Pointer','Portuguese Podengo','The Saluki','Samoyed','Siberian Husky','Sloughis','Stabyhouns',\n",
    "        'Sussex Spaniel','Treeing Walker Coonhound','Vizslas','Wirehaired Pointing Griffon','Basenji','Beagle',\n",
    "        'Cardigan Welsh Corgi','Cocker Spaniel','Dandie Dinmont Terrier','English Cocker Spaniel','Finnish Spitz',\n",
    "        'German Pinscher','Kai Kens','Kerry Blue Terriers','Miniature Bull Terrier','Norwegian Buhunds',\n",
    "        'Pembroke Welsh Corgi','Petit Bassett Griffon Vendeen','Polish Lowland Sheepdog','Portuguese Podengo (Medio)',\n",
    "        'Portuguese Water Dog','Pyrenean Shepherd','Sealyham Terrier','Shetland Sheepdog','Skye Terrier',\n",
    "        'Soft Coated Wheaten Terrier','Spanish Water Dogs','Staffordshire Bull Terrier','Standard Schnauzer',\n",
    "        'Tibetan Terrier','Treeing Tennessee Brindle','Welsh Springer Spaniel','West Highland White Terrier',\n",
    "        'Whippet','Wire Fox Terrier','Affenpinscher','American Eskimo','Miniature American Eskimo',\n",
    "        'Toy American Eskimo','Australian Terrier','Bichon Frise','Bolognese','Border Terrier','Boston Terrier',\n",
    "        'Brussels Griffon','Cairn Terrier','Cavalier King Charles Spaniel','Cesky Terrier','Chihuahua',\n",
    "        'Chinese Crested','Coton de Tulear','Dachshund','English Toy Spaniel','French Bulldog','Havanese',\n",
    "        'Italian Greyhound','Japanese Chin','Lancashire Heeler','Lhasa Apso','Lowchen','Maltese','Manchester Terrier',\n",
    "        'Standard Manchester Terrier','Toy Manchester Terrier','Miniature Pinscher','Miniature Schnauzer',\n",
    "        'Norfolk Terrier','Norwich Terrier','Papillon','Parson Russell Terrier','Pekingese','Pomeranian','Poodle',\n",
    "        'Miniature Poodle','Toy Poodle','Portuguese Podengo (Pequeno)','Pug','Rat Terrier','Schipperke',\n",
    "        'Scottish Terrier','Shiba Inu','Shih Tzu','Silky Terrier','Smooth Fox Terrier','Tibetan Spaniel',\n",
    "        'Toy Fox Terrier','Yorkshire Terrier','Xoloitzcuintli']\n",
    "\n",
    "    l2=['Large','Large','Large','Large','Large','Large','Large','Large','Large','Large','Large','Large','Large',\n",
    "        'Large','Large','Large','Large','Large','Large','Medium Large','Medium Large','Medium Large','Medium Large',\n",
    "        'Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large',\n",
    "        'Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large',\n",
    "        'Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large','Medium Large',\n",
    "        'Medium Large','Medium Large','Medium Large','Medium Large','Medium','Medium','Medium','Medium','Medium',\n",
    "        'Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium',\n",
    "        'Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium',\n",
    "        'Medium','Medium','Medium','Medium','Medium','Medium','Medium','Medium','Small Medium','Small Medium',\n",
    "        'Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium',\n",
    "        'Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium',\n",
    "        'Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium',\n",
    "        'Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium','Small Medium',\n",
    "        'Small Medium','Small Medium','Small','Small','Small','Small','Small','Small','Small','Small','Small',\n",
    "        'Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small',\n",
    "        'Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small',\n",
    "        'Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small','Small',\n",
    "        'Small','Small','Small','Small','Small']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['size']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    '''\n",
    "    #dangerous dogs\n",
    "    l1=['Dalmatian','Great Dane','Presa Canario','Doberman Pinsch','Chow Chow','Alaskan Malamute','Wolf-Dog Hybrid',\n",
    "        'German Shepherd','Rottweiler','Pit Bull']\n",
    "    l2=['Dangerous Dog','Dangerous Dog','Dangerous Dog','Dangerous Dog','Dangerous Dog','Dangerous Dog',\n",
    "        'Dangerous Dog','Dangerous Dog','Dangerous Dog','Dangerous Dog']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['dangerous']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    \n",
    "    ####Smart\n",
    "    l1=['Bloodhound','Border Collie','Doberman Pinscher','German Shepherd Dog','Golden Retriever',\n",
    "        'Labrador Retriever','Papillon','Poodle','Rottweiler','Shetland Sheepdog']\n",
    "    l2=['Smart','Smart','Smart','Smart','Smart','Smart','Smart','Smart','Smart','Smart']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['smart']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    \n",
    "    ####Kids\n",
    "    l1=['Beagle','Boxer','Bull Terrier','Bulldog','Golden Retriever','Labrador Retriever','Newfoundland',\n",
    "        'Soft Coated Wheaten Terrier','Weimaraner']\n",
    "    l2=['Kids','Kids','Kids','Kids','Kids','Kids','Kids','Kids','Kids']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['kids']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    \n",
    "    ####Hypo\n",
    "    l1=['Afghan Hound','American Hairless Terrier','Bedlington Terrier','Bichon Frise','Chinese Crested',\n",
    "        'Coton de Tulear','Giant Schnauzer','Irish Water Spaniel','Kerry Blue Terrier','Lagotto Romagnolo',\n",
    "        'Maltese','Peruvian Inca Orchid','Poodle','Portuguese Water Dog','Soft Coated Wheaten Terrier',\n",
    "        'Standard Schnauzer','Xoloitzcuintli']\n",
    "    l2=['Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic',\n",
    "        'Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic',\n",
    "        'Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic','Hypoallergenic']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['hypo']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    \n",
    "    ####Family\n",
    "    l1=['Beagle','Brussels Griffon','Bulldog','Collie','French Bulldog','Golden Retriever','Irish Setter',\n",
    "        'Labrador Retriever','Newfoundland','Pug']\n",
    "    l2=['Family','Family','Family','Family','Family','Family','Family','Family','Family','Family']\n",
    "    \n",
    "    l3=pd.DataFrame(l1)\n",
    "    l3['breed1']=pd.DataFrame(l1)\n",
    "    l3['family']=pd.DataFrame(l2)\n",
    "    l3.drop(0,axis=1,inplace=True)\n",
    "    l3['breed1']=l3['breed1'].str.upper()\n",
    "    \n",
    "    data=pd.merge(data, l3, on = 'breed1',how='left')\n",
    "    '''\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAge(x):\n",
    "    if pd.notnull(x):\n",
    "        value = int(x.split(' ')[0])\n",
    "        if x.endswith('day') or x.endswith('days'):\n",
    "            return value\n",
    "        if x.endswith('weeks') or x.endswith('week'):\n",
    "            return value*7\n",
    "        if x.endswith('month') or x.endswith('months'):\n",
    "            return value*30\n",
    "        if x.endswith('year') or x.endswith('years'):\n",
    "            return value*365\n",
    "    return -1\n",
    "\n",
    "def cleanBreed(x):\n",
    "    x = x.replace('Mix','')\n",
    "    x = x.replace('Shorthair','')\n",
    "    x = x.replace('Medium Hair','')\n",
    "    x = x.replace('Longhair','')\n",
    "    x = x.replace('  ',' ')\n",
    "    x = x.replace('   ',' ')\n",
    "    x = x.replace('    ',' ')\n",
    "    x = x.strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def cleanColor(x):\n",
    "    x = x.replace('Tabby','')\n",
    "    x = x.replace('  ',' ')\n",
    "    x = x.replace('   ',' ')\n",
    "    x = x.replace('    ',' ')\n",
    "    x = x.strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def splitBreed(x, i):\n",
    "    x = x.split('/')\n",
    "    if len(x) >= (i+1):\n",
    "        return x[i]\n",
    "    return 'null'\n",
    "\n",
    "def getHairType(x):\n",
    "    if pd.notnull(x) and 'Shorthair' in x:\n",
    "        return 1\n",
    "    if pd.notnull(x) and 'Medium Hair' in x:\n",
    "        return 2\n",
    "    if pd.notnull(x) and 'Longhair' in x:\n",
    "        return 3\n",
    "    return -1\n",
    "\n",
    "def getDayPeriod(x):\n",
    "    if x.hour < 6:\n",
    "        return 0\n",
    "    if x.hour >= 6 and x.hour < 12:\n",
    "        return 1\n",
    "    if x.hour >= 12 and x.hour < 18:\n",
    "        return 2\n",
    "    if x.hour >= 18:\n",
    "        return 3\n",
    "    return -1\n",
    "\n",
    "def getSeason(x):\n",
    "    if 4<=x<=6:\n",
    "        return 1\n",
    "    if 7<=x<=9:\n",
    "        return 2\n",
    "    if 10<=x<=12:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def getHolidays(day, month):\n",
    "    #confederate Heroes\n",
    "    if month==1 and day==19:\n",
    "        return 1\n",
    "    #Texas Independance\n",
    "    if month==3 and day==2:\n",
    "        return 2\n",
    "    #San Jacinto Day        \n",
    "    if month==4 and day==21:\n",
    "        return 3                  \n",
    "    #Mothers Day        \n",
    "    if month==5 and day==10:\n",
    "        return 4              \n",
    "    #Emancipation Day        \n",
    "    if month==6 and day==19:\n",
    "        return 5\n",
    "    #Fathers Day        \n",
    "    if month==6 and 18<=day<=22:\n",
    "        return 6\n",
    "    #Lyndon day       \n",
    "    if month==8 and day==27:\n",
    "        return 7\n",
    "    #Veterans day       \n",
    "    if month==11 and day==11:\n",
    "        return 8\n",
    "    #ThanksGiving                    \n",
    "    if month==11 and 25<=day<=27:\n",
    "        return 9\n",
    "    #Christmas                    \n",
    "    if month==12 and 23<=day<=27:\n",
    "        return 10\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mostRepresentativeBreeds(x):\n",
    "\n",
    "    if x == \"Shetland Sheepdog\":\n",
    "        return 1\n",
    "    if x == \"Pit Bull\":\n",
    "        return 2\n",
    "    if x == \"Lhasa Apso\":\n",
    "        return 3\n",
    "    if x == \"Chihuahua Shorthair\":\n",
    "        return 4\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_features(data, train = False):\n",
    "    if train:\n",
    "        data.drop('OutcomeSubtype', axis=1, inplace=True)\n",
    "        \n",
    "    ###### RETIRANDO O OUTCOMESUBTYPE O NAME DO TREINO E TESTE ######\n",
    "    data['has_name'] = data['Name'].apply(lambda x :  pd.notnull(x) )\n",
    "    data.drop(['Name'], axis=1, inplace=True)\n",
    "    \n",
    "    #Date\n",
    "    data['DateTime'] = data['DateTime'].apply(lambda x : pd.tslib.Timestamp(x, tz=None))\n",
    "    data['day'] = data['DateTime'].apply(lambda x : x.day)\n",
    "    data['month'] = data['DateTime'].apply(lambda x : x.month)\n",
    "    data['year'] = data['DateTime'].apply(lambda x : x.year)\n",
    "    data['hour'] = data['DateTime'].apply(lambda x : x.hour)\n",
    "    data['minute'] = data['DateTime'].apply(lambda x : x.minute)\n",
    "    data['day_of_week'] = data['DateTime'].apply(lambda x : x.weekday())\n",
    "    data['weekday'] = data['DateTime'].apply(lambda x : x.weekday() < 5)\n",
    "    data['working_hour'] = data['DateTime'].apply(lambda x : x.hour >= 8 and x.hour <= 18)\n",
    "    data['madrugada'] = data['DateTime'].apply(lambda x : x.hour < 6)\n",
    "    data['manha'] = data['DateTime'].apply(lambda x : x.hour >= 6 and x.hour < 12)\n",
    "    data['tarde'] = data['DateTime'].apply(lambda x : x.hour >= 12 and x.hour < 18)\n",
    "    data['noite'] = data['DateTime'].apply(lambda x : x.hour >= 18)\n",
    "    #data['quarter'] = data['DateTime'].apply(lambda x : x.quarter)#<<<\n",
    "    #data['weekofyear'] = data['DateTime'].apply(lambda x : x.weekofyear)#<<<\n",
    "    #data['season'] = data['month'].apply(lambda x : getSeason(x))#<<<\n",
    "    #data['holiday'] = data['DateTime'].apply(lambda x : getHolidays(x.day, x.month))#<<<\n",
    "    '''\n",
    "    data['day_period'] = data['DateTime'].apply(lambda x : getDayPeriod(x))\n",
    "    '''\n",
    "    data.drop(['DateTime'], axis=1, inplace=True)\n",
    "    \n",
    "    #Age\n",
    "    data['age'] = data['AgeuponOutcome'].apply(lambda x : getAge(x))\n",
    "    data['puppy'] = data['age'].apply(lambda x : x <= 365)\n",
    "    data['adolescence'] = data['age'].apply(lambda x : x > 365 and x <= 730)\n",
    "    data['adulthood'] = data['age'].apply(lambda x : x > 730 and x <= 2920)\n",
    "    data['senior'] = data['age'].apply(lambda x : x > 2920)\n",
    "    data.drop(['AgeuponOutcome'], axis=1, inplace=True)\n",
    "    \n",
    "    #Sex\n",
    "    data['male'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and x.endswith('Male'))\n",
    "    data['female'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and x.endswith('Female'))\n",
    "    data['castrated'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and (x.startswith('Spayed') \n",
    "                                                                                   or x.startswith('Neutered')))\n",
    "    data.drop(['SexuponOutcome'], axis=1, inplace=True)\n",
    "    '''\n",
    "    data['sex'] = data['SexuponOutcome'].apply(lambda x : 1 if pd.notnull(x) and x.endswith('Male') else 0)\n",
    "    data['intact'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and x.startswith('Intact'))\n",
    "    data['spayed'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and x.startswith('Spayed'))\n",
    "    data['neutered'] = data['SexuponOutcome'].apply(lambda x : pd.notnull(x) and x.startswith('Neutered'))\n",
    "    data.drop(['SexuponOutcome'], axis=1, inplace=True)\n",
    "    '''\n",
    "    \n",
    "    #Breed\n",
    "    \n",
    "    data['mix'] = data['Breed'].apply(lambda x : pd.notnull(x) and x.endswith('Mix'))\n",
    "    data['shorthair'] = data['Breed'].apply(lambda x : pd.notnull(x) and 'Shorthair' in x)\n",
    "    data['mediumhair'] = data['Breed'].apply(lambda x : pd.notnull(x) and 'Medium Hair' in x)\n",
    "    data['longhair'] = data['Breed'].apply(lambda x : pd.notnull(x) and 'Longhair' in x)\n",
    "    '''\n",
    "    data['mix'] = data['Breed'].apply(lambda x : pd.notnull(x) and x.endswith('Mix'))\n",
    "    data['hair'] = data['Breed'].apply(lambda x : getHairType(x))\n",
    "    '''\n",
    "    data['Breed'] = data['Breed'].apply(lambda x : cleanBreed(x))\n",
    "    data['breed1'] = data['Breed'].apply(lambda x : splitBreed(x, 0).upper())\n",
    "    data['breed2'] = data['Breed'].apply(lambda x : splitBreed(x, 1).upper())\n",
    "    data.drop(['Breed'], axis=1, inplace=True)\n",
    "    data['specialBreeds'] = data['breed1'].apply(lambda x : mostRepresentativeBreeds(x))\n",
    "    \n",
    "    #Color\n",
    "    data['tabby'] = data['Color'].apply(lambda x : pd.notnull(x) and 'Tabby' in x)\n",
    "    data['Color'] = data['Color'].apply(lambda x : cleanColor(x))\n",
    "    data['color1'] = data['Color'].apply(lambda x : splitBreed(x, 0))\n",
    "    data['color2'] = data['Color'].apply(lambda x : splitBreed(x, 1))\n",
    "    #data['unicolor'] = data['color2'].apply(lambda x : x == 'null')#<<<\n",
    "    \n",
    "    \n",
    "    data.drop(['Color'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo os arquivos do treino e test. <br />\n",
    "Biblioteca utilizada: <br />\n",
    "Pandas: http://pandas.pydata.org/<br />\n",
    "Função utilizada: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:14.242000",
     "start_time": "2016-06-29T15:00:14.174000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv', index_col='AnimalID')\n",
    "test = pd.read_csv('input/test.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getValueFrequency(group, group2, outcomeType, row):\n",
    "    date = row['Date']\n",
    "    animalType = row['AnimalType']\n",
    "    try:\n",
    "        g = group.xs((animalType, date), level=('AnimalType', 'Date'))['DateTime']\n",
    "        g2 = group2.xs((outcomeType, animalType, date), level=('OutcomeType', 'AnimalType', 'Date'))['DateTime']\n",
    "    except:\n",
    "        return 0\n",
    "    if g.values.size > 0 and g2.values.size > 0:\n",
    "        val = g.values[0]\n",
    "        val2 = g2.values[0]\n",
    "        return val2/(val * 1.0)\n",
    "    return 0\n",
    "\n",
    "def setDate(x):\n",
    "    x = x.date().replace(day=1)\n",
    "    return x\n",
    "\n",
    "def generateFrequencyFeatures(data, test):\n",
    "    data['DateTime'] = data['DateTime'].apply(lambda x : pd.tslib.Timestamp(x, tz=None))\n",
    "    data['Date'] = data['DateTime'].apply(lambda x : setDate(x))\n",
    "    \n",
    "    test['DateTime'] = test['DateTime'].apply(lambda x : pd.tslib.Timestamp(x, tz=None))\n",
    "    test['Date'] = test['DateTime'].apply(lambda x : setDate(x))\n",
    "    \n",
    "    counts = data['Date'].value_counts()\n",
    "    counts_test = test['Date'].value_counts()\n",
    "    data['outcomes'] = data['Date'].apply(lambda x : counts[x]/(len(data) * 1.0))\n",
    "    test['outcomes'] = test['Date'].apply(lambda x : counts_test[x]/(len(test) * 1.0))\n",
    "    \n",
    "    group2 = data.groupby(['Date', 'AnimalType','OutcomeType']).count()\n",
    "    group = data.groupby(['Date', 'AnimalType']).count()\n",
    "    data['Transfer'] = data.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Transfer', x),axis=1)\n",
    "    test['Transfer'] = test.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Transfer', x),axis=1)\n",
    "    data['Return_to_owner'] = data.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Return_to_owner', x),axis=1)\n",
    "    test['Return_to_owner'] = test.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Return_to_owner', x),axis=1)\n",
    "    data['Euthanasia'] = data.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Euthanasia', x),axis=1)\n",
    "    test['Euthanasia'] = test.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Euthanasia', x),axis=1)\n",
    "    data['Adoption'] = data.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Adoption', x),axis=1)\n",
    "    test['Adoption'] = test.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Adoption', x),axis=1)\n",
    "    data['Died'] = data.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Died', x),axis=1)\n",
    "    test['Died'] = test.apply(lambda x,g=group,g2=group2 : getValueFrequency(g, g2, 'Died', x),axis=1)\n",
    "    \n",
    "    #data['outcomes'] = data['Date'].apply(lambda x : data[data['Date'] == x].size)\n",
    "    #data.drop(['Date'], axis=1, inplace=True)\n",
    "    #test.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValueFrequency2(group, counts, outcomeType, breed):\n",
    "    try:\n",
    "        g = group.xs((outcomeType, breed), level=('OutcomeType', 'breed1'))['Date']\n",
    "    except:\n",
    "        return 0\n",
    "    if g.values.size > 0:\n",
    "        val = g.values[0]\n",
    "        return val/(counts[breed] * 1.0)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def generateFrequencyFeatures2(data, test):\n",
    "\n",
    "    counts = data['breed1'].value_counts()\n",
    "    \n",
    "    group = data.groupby(['breed1', 'OutcomeType']).count()\n",
    "    \n",
    "    data['Transfer_breed'] = data['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Transfer', x))\n",
    "    test['Transfer_breed'] = test['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Transfer', x))\n",
    "    data['Return_to_owner_breed'] = data['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Return_to_owner', x))\n",
    "    test['Return_to_owner_breed'] = test['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Return_to_owner', x))\n",
    "    data['Euthanasia_breed'] = data['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Euthanasia', x))\n",
    "    test['Euthanasia_breed'] = test['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Euthanasia', x))\n",
    "    data['Adoption_breed'] = data['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Adoption', x))\n",
    "    test['Adoption_breed'] = test['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Adoption', x))\n",
    "    data['Died_breed'] = data['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Died', x))\n",
    "    test['Died_breed'] = test['breed1'].apply(lambda x,g=group,c=counts : getValueFrequency2(g, c, 'Died', x))\n",
    "    \n",
    "    #data['outcomes'] = data['Date'].apply(lambda x : data[data['Date'] == x].size)\n",
    "    #data.drop(['Date'], axis=1, inplace=True)\n",
    "    #test.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnimalID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A671945</th>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A656520</th>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A686464</th>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A683430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A667013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name             DateTime      OutcomeType OutcomeSubtype  \\\n",
       "AnimalID                                                                 \n",
       "A671945   Hambone  2014-02-12 18:22:00  Return_to_owner            NaN   \n",
       "A656520     Emily  2013-10-13 12:44:00       Euthanasia      Suffering   \n",
       "A686464    Pearce  2015-01-31 12:28:00         Adoption         Foster   \n",
       "A683430       NaN  2014-07-11 19:09:00         Transfer        Partner   \n",
       "A667013       NaN  2013-11-15 12:52:00         Transfer        Partner   \n",
       "\n",
       "         AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "AnimalID                                            \n",
       "A671945         Dog  Neutered Male         1 year   \n",
       "A656520         Cat  Spayed Female         1 year   \n",
       "A686464         Dog  Neutered Male        2 years   \n",
       "A683430         Cat    Intact Male        3 weeks   \n",
       "A667013         Dog  Neutered Male        2 years   \n",
       "\n",
       "                                Breed        Color  \n",
       "AnimalID                                            \n",
       "A671945         Shetland Sheepdog Mix  Brown/White  \n",
       "A656520        Domestic Shorthair Mix  Cream Tabby  \n",
       "A686464                  Pit Bull Mix   Blue/White  \n",
       "A683430        Domestic Shorthair Mix   Blue Cream  \n",
       "A667013   Lhasa Apso/Miniature Poodle          Tan  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo a coluna **OutcomeSubtype**, porque ela não existe no test. <br />\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:14.331000",
     "start_time": "2016-06-29T15:00:14.323000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Date</th>\n",
       "      <th>outcomes</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>has_name</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>breed2</th>\n",
       "      <th>specialBreeds</th>\n",
       "      <th>tabby</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>Transfer_breed</th>\n",
       "      <th>Return_to_owner_breed</th>\n",
       "      <th>Euthanasia_breed</th>\n",
       "      <th>Adoption_breed</th>\n",
       "      <th>Died_breed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.229703</td>\n",
       "      <td>0.330693</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>0.411881</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>0.260052</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>0.447520</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.231959</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.448454</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>SIBERIAN HUSKY</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Black</td>\n",
       "      <td>Tan</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.044794</td>\n",
       "      <td>0.450363</td>\n",
       "      <td>0.003632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.033258</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Brown</td>\n",
       "      <td>null</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.233577</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>0.441606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tricolor</td>\n",
       "      <td>null</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>0.039892</td>\n",
       "      <td>0.257198</td>\n",
       "      <td>0.261036</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>White</td>\n",
       "      <td>null</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.454839</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AnimalType        Date  outcomes  Transfer  Return_to_owner  Euthanasia  \\\n",
       "ID                                                                           \n",
       "1         Dog  2015-10-01  0.036837  0.229703         0.330693    0.025743   \n",
       "2         Dog  2014-07-01  0.048010  0.231959         0.237113    0.080756   \n",
       "3         Cat  2016-01-01  0.033258  0.289062         0.046875    0.058594   \n",
       "4         Dog  2013-12-01  0.034742  0.250000         0.233577    0.074818   \n",
       "5         Dog  2015-09-01  0.039892  0.257198         0.261036    0.038388   \n",
       "\n",
       "    Adoption      Died has_name  day    ...              breed2  \\\n",
       "ID                                      ...                       \n",
       "1   0.411881  0.001980     True   12    ...                NULL   \n",
       "2   0.448454  0.001718     True   26    ...      SIBERIAN HUSKY   \n",
       "3   0.597656  0.007812     True   13    ...                NULL   \n",
       "4   0.441606  0.000000     True   28    ...                NULL   \n",
       "5   0.437620  0.005758     True   24    ...                NULL   \n",
       "\n",
       "    specialBreeds  tabby    color1  color2 Transfer_breed  \\\n",
       "ID                                                          \n",
       "1               0  False       Red   White       0.247520   \n",
       "2               0  False     Black     Tan       0.214286   \n",
       "3               0   True     Brown    null       0.502843   \n",
       "4               0  False  Tricolor    null       0.209302   \n",
       "5               0  False     White    null       0.206452   \n",
       "\n",
       "   Return_to_owner_breed Euthanasia_breed Adoption_breed Died_breed  \n",
       "ID                                                                   \n",
       "1               0.260052         0.042820       0.447520   0.002089  \n",
       "2               0.286925         0.044794       0.450363   0.003632  \n",
       "3               0.042209         0.064180       0.377469   0.013299  \n",
       "4               0.186047         0.023256       0.581395   0.000000  \n",
       "5               0.303226         0.035484       0.454839   0.000000  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateFrequencyFeatures(train,test)\n",
    "generate_features(train, True)\n",
    "generate_features(test)\n",
    "generateFrequencyFeatures2(train,test)\n",
    "'''\n",
    "train = generateBreedFeatures(train)\n",
    "test = generateBreedFeatures(test)\n",
    "'''\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcomes</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>age</th>\n",
       "      <th>specialBreeds</th>\n",
       "      <th>Transfer_breed</th>\n",
       "      <th>Return_to_owner_breed</th>\n",
       "      <th>Euthanasia_breed</th>\n",
       "      <th>Adoption_breed</th>\n",
       "      <th>Died_breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.0</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "      <td>26729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.035781</td>\n",
       "      <td>0.352501</td>\n",
       "      <td>0.179056</td>\n",
       "      <td>0.058177</td>\n",
       "      <td>0.402896</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>15.698343</td>\n",
       "      <td>6.925736</td>\n",
       "      <td>2014.430731</td>\n",
       "      <td>14.445396</td>\n",
       "      <td>27.681170</td>\n",
       "      <td>3.106364</td>\n",
       "      <td>793.595308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352501</td>\n",
       "      <td>0.179056</td>\n",
       "      <td>0.058177</td>\n",
       "      <td>0.402896</td>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.117528</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.075219</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>8.770496</td>\n",
       "      <td>3.495869</td>\n",
       "      <td>0.741408</td>\n",
       "      <td>3.337331</td>\n",
       "      <td>18.189427</td>\n",
       "      <td>2.046001</td>\n",
       "      <td>1082.662074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134405</td>\n",
       "      <td>0.129233</td>\n",
       "      <td>0.032803</td>\n",
       "      <td>0.084725</td>\n",
       "      <td>0.006512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.367041</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243729</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.001957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.035392</td>\n",
       "      <td>0.274583</td>\n",
       "      <td>0.237255</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297674</td>\n",
       "      <td>0.206422</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.007493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.039882</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.269397</td>\n",
       "      <td>0.070611</td>\n",
       "      <td>0.441606</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.447520</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>0.370884</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7300.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           outcomes      Transfer  Return_to_owner    Euthanasia  \\\n",
       "count  26729.000000  26729.000000     26729.000000  26729.000000   \n",
       "mean       0.035781      0.352501         0.179056      0.058177   \n",
       "std        0.006677      0.139237         0.117528      0.019676   \n",
       "min        0.020352      0.176471         0.013774      0.010582   \n",
       "25%        0.031352      0.250000         0.044872      0.047423   \n",
       "50%        0.035392      0.274583         0.237255      0.060109   \n",
       "75%        0.039882      0.483471         0.269397      0.070611   \n",
       "max        0.048936      0.712375         0.370884      0.110390   \n",
       "\n",
       "           Adoption          Died           day         month          year  \\\n",
       "count  26729.000000  26729.000000  26729.000000  26729.000000  26729.000000   \n",
       "mean       0.402896      0.007370     15.698343      6.925736   2014.430731   \n",
       "std        0.075219      0.006881      8.770496      3.495869      0.741408   \n",
       "min        0.153846      0.000000      1.000000      1.000000   2013.000000   \n",
       "25%        0.367041      0.002155      8.000000      4.000000   2014.000000   \n",
       "50%        0.411658      0.005190     16.000000      7.000000   2014.000000   \n",
       "75%        0.441606      0.010309     23.000000     10.000000   2015.000000   \n",
       "max        0.597656      0.025918     31.000000     12.000000   2016.000000   \n",
       "\n",
       "               hour        minute   day_of_week           age  specialBreeds  \\\n",
       "count  26729.000000  26729.000000  26729.000000  26729.000000        26729.0   \n",
       "mean      14.445396     27.681170      3.106364    793.595308            0.0   \n",
       "std        3.337331     18.189427      2.046001   1082.662074            0.0   \n",
       "min        0.000000      0.000000      0.000000     -1.000000            0.0   \n",
       "25%       12.000000     12.000000      1.000000     60.000000            0.0   \n",
       "50%       15.000000     27.000000      3.000000    365.000000            0.0   \n",
       "75%       17.000000     43.000000      5.000000   1095.000000            0.0   \n",
       "max       23.000000     59.000000      6.000000   7300.000000            0.0   \n",
       "\n",
       "       Transfer_breed  Return_to_owner_breed  Euthanasia_breed  \\\n",
       "count    26729.000000           26729.000000      26729.000000   \n",
       "mean         0.352501               0.179056          0.058177   \n",
       "std          0.134405               0.129233          0.032803   \n",
       "min          0.000000               0.000000          0.000000   \n",
       "25%          0.243729               0.042209          0.042820   \n",
       "50%          0.297674               0.206422          0.064180   \n",
       "75%          0.502843               0.286925          0.064180   \n",
       "max          1.000000               1.000000          0.500000   \n",
       "\n",
       "       Adoption_breed    Died_breed  \n",
       "count    26729.000000  26729.000000  \n",
       "mean         0.402896      0.007370  \n",
       "std          0.084725      0.006512  \n",
       "min          0.000000      0.000000  \n",
       "25%          0.377469      0.001957  \n",
       "50%          0.377469      0.007493  \n",
       "75%          0.447520      0.013299  \n",
       "max          1.000000      0.090909  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "breed_train = np.append(train['breed1'], train['breed2'])\n",
    "breed_test = np.append(test['breed1'], test['breed2'])\n",
    "le = LabelEncoder().fit(np.append(breed_train, breed_test))\n",
    "train['breed1'] = le.transform(train['breed1'])\n",
    "test['breed1'] = le.transform(test['breed1'])\n",
    "train['breed2'] = le.transform(train['breed2'])\n",
    "test['breed2'] = le.transform(test['breed2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_train = np.append(train['color1'], train['color2'])\n",
    "color_test = np.append(test['color1'], test['color2'])\n",
    "le = LabelEncoder().fit(np.append(color_train, color_test))\n",
    "train['color1'] = le.transform(train['color1'])\n",
    "test['color1'] = le.transform(test['color1'])\n",
    "train['color2'] = le.transform(train['color2'])\n",
    "test['color2'] = le.transform(test['color2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['AnimalType','Date']:\n",
    "    le = LabelEncoder().fit(np.append(train[col], test[col]))\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T13:44:04.620000",
     "start_time": "2016-06-29T13:44:04.616000"
    }
   },
   "source": [
    "Convertendo campo categórico para número inteiro, porque os modelos matemáricos do sklearn só aceitam números. <br />\n",
    "Utilizando: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o TARGET do meu treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:14.674000",
     "start_time": "2016-06-29T15:00:14.653000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train['OutcomeType']\n",
    "data   = train.drop('OutcomeType', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Date</th>\n",
       "      <th>outcomes</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>has_name</th>\n",
       "      <th>...</th>\n",
       "      <th>breed2</th>\n",
       "      <th>specialBreeds</th>\n",
       "      <th>tabby</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>Transfer_breed</th>\n",
       "      <th>Return_to_owner_breed</th>\n",
       "      <th>Euthanasia_breed</th>\n",
       "      <th>Adoption_breed</th>\n",
       "      <th>Died_breed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnimalID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A671945</th>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024356</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.269397</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.433190</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A656520</th>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.022277</td>\n",
       "      <td>0.064356</td>\n",
       "      <td>0.393564</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A686464</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.286538</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>0.243729</td>\n",
       "      <td>0.320871</td>\n",
       "      <td>0.135826</td>\n",
       "      <td>0.295788</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A683430</th>\n",
       "      <td>Transfer</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A667013</th>\n",
       "      <td>Transfer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030042</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.237255</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.390196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              OutcomeType  AnimalType  Date  outcomes  Transfer  \\\n",
       "AnimalID                                                          \n",
       "A671945   Return_to_owner           1     4  0.024356  0.232759   \n",
       "A656520        Euthanasia           0     0  0.036440  0.500000   \n",
       "A686464          Adoption           1    15  0.028434  0.184615   \n",
       "A683430          Transfer           0     9  0.048936  0.483471   \n",
       "A667013          Transfer           1     1  0.030042  0.309804   \n",
       "\n",
       "          Return_to_owner  Euthanasia  Adoption      Died has_name    ...      \\\n",
       "AnimalID                                                              ...       \n",
       "A671945          0.269397    0.062500  0.433190  0.002155     True    ...       \n",
       "A656520          0.022277    0.064356  0.393564  0.019802     True    ...       \n",
       "A686464          0.286538    0.061538  0.465385  0.001923     True    ...       \n",
       "A683430          0.013774    0.046832  0.438017  0.017906    False    ...       \n",
       "A667013          0.237255    0.062745  0.390196  0.000000    False    ...       \n",
       "\n",
       "          breed2  specialBreeds  tabby  color1  color2  Transfer_breed  \\\n",
       "AnimalID                                                                 \n",
       "A671945      154              0  False      15      55        0.243243   \n",
       "A656520      154              0   True      25      58        0.502843   \n",
       "A686464      154              0  False       7      55        0.243729   \n",
       "A683430      154              0  False       9      58        0.502843   \n",
       "A667013      144              0  False      50      58        0.614286   \n",
       "\n",
       "         Return_to_owner_breed Euthanasia_breed Adoption_breed Died_breed  \n",
       "AnimalID                                                                   \n",
       "A671945               0.378378         0.081081       0.297297   0.000000  \n",
       "A656520               0.042209         0.064180       0.377469   0.013299  \n",
       "A686464               0.320871         0.135826       0.295788   0.003786  \n",
       "A683430               0.042209         0.064180       0.377469   0.013299  \n",
       "A667013               0.271429         0.014286       0.085714   0.014286  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando o método random forest classifier do sklearn.<br />\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Date</th>\n",
       "      <th>outcomes</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>has_name</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>breed2</th>\n",
       "      <th>specialBreeds</th>\n",
       "      <th>tabby</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>Transfer_breed</th>\n",
       "      <th>Return_to_owner_breed</th>\n",
       "      <th>Euthanasia_breed</th>\n",
       "      <th>Adoption_breed</th>\n",
       "      <th>Died_breed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.229703</td>\n",
       "      <td>0.330693</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>0.411881</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>55</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>0.260052</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>0.447520</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.231959</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.448454</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.044794</td>\n",
       "      <td>0.450363</td>\n",
       "      <td>0.003632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.033258</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>0.377469</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.233577</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>0.441606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.039892</td>\n",
       "      <td>0.257198</td>\n",
       "      <td>0.261036</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.454839</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AnimalType  Date  outcomes  Transfer  Return_to_owner  Euthanasia  \\\n",
       "ID                                                                      \n",
       "1            1    24  0.036837  0.229703         0.330693    0.025743   \n",
       "2            1     9  0.048010  0.231959         0.237113    0.080756   \n",
       "3            0    27  0.033258  0.289062         0.046875    0.058594   \n",
       "4            1     2  0.034742  0.250000         0.233577    0.074818   \n",
       "5            1    23  0.039892  0.257198         0.261036    0.038388   \n",
       "\n",
       "    Adoption      Died has_name  day    ...      breed2  specialBreeds  tabby  \\\n",
       "ID                                      ...                                     \n",
       "1   0.411881  0.001980     True   12    ...         154              0  False   \n",
       "2   0.448454  0.001718     True   26    ...         197              0  False   \n",
       "3   0.597656  0.007812     True   13    ...         154              0   True   \n",
       "4   0.441606  0.000000     True   28    ...         154              0  False   \n",
       "5   0.437620  0.005758     True   24    ...         154              0  False   \n",
       "\n",
       "    color1  color2 Transfer_breed Return_to_owner_breed Euthanasia_breed  \\\n",
       "ID                                                                         \n",
       "1       41      55       0.247520              0.260052         0.042820   \n",
       "2        2      50       0.214286              0.286925         0.044794   \n",
       "3       15      58       0.502843              0.042209         0.064180   \n",
       "4       54      58       0.209302              0.186047         0.023256   \n",
       "5       55      58       0.206452              0.303226         0.035484   \n",
       "\n",
       "   Adoption_breed Died_breed  \n",
       "ID                            \n",
       "1        0.447520   0.002089  \n",
       "2        0.450363   0.003632  \n",
       "3        0.377469   0.013299  \n",
       "4        0.581395   0.000000  \n",
       "5        0.454839   0.000000  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7248915  -0.71801171 -0.71191939]\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=11, n_estimators=175, learning_rate=0.05, silent=1, objective='multi:softprob',\n",
    "                        subsample=0.8,colsample_bytree=0.6)\n",
    "fit = clf.fit(data, target)\n",
    "proba = fit.predict_proba(test)\n",
    "print cross_validation.cross_val_score(clf, data, target, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:15.070000",
     "start_time": "2016-06-29T15:00:14.687000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n=100 d=2] [-0.83689628 -0.8283312  -0.82434193]\n",
      "[n=100 d=3] [-0.80715529 -0.79665308 -0.79570285]\n",
      "[n=100 d=4] [-0.78743215 -0.77728835 -0.775879  ]\n",
      "[n=100 d=5] [-0.77447217 -0.76436393 -0.76240123]\n",
      "[n=100 d=6] [-0.76382459 -0.75478933 -0.75283341]\n",
      "[n=100 d=7] [-0.75579189 -0.74788492 -0.74550681]\n",
      "[n=100 d=8] [-0.75032567 -0.74342676 -0.73998716]\n",
      "[n=100 d=9] [-0.74589829 -0.74002025 -0.73505561]\n",
      "[n=100 d=10] [-0.74262882 -0.7369784  -0.73211477]\n",
      "[n=125 d=2] [-0.81801477 -0.80860395 -0.80604292]\n",
      "[n=125 d=3] [-0.7904067  -0.77933786 -0.77981493]\n",
      "[n=125 d=4] [-0.77216697 -0.76209774 -0.76152315]\n",
      "[n=125 d=5] [-0.76020693 -0.75077311 -0.74964862]\n",
      "[n=125 d=6] [-0.75071484 -0.74204119 -0.7399109 ]\n",
      "[n=125 d=7] [-0.74330155 -0.73556973 -0.73321756]\n",
      "[n=125 d=8] [-0.73867263 -0.73192538 -0.72806524]\n",
      "[n=125 d=9] [-0.73410601 -0.72909497 -0.72436127]\n",
      "[n=125 d=10] [-0.73171263 -0.72712343 -0.72135836]\n",
      "[n=150 d=2] [-0.80575265 -0.79642054 -0.79479188]\n",
      "[n=150 d=3] [-0.78058333 -0.76984909 -0.77015914]\n",
      "[n=150 d=4] [-0.76347796 -0.7539354  -0.75371249]\n",
      "[n=150 d=5] [-0.75273907 -0.74333734 -0.74295647]\n",
      "[n=150 d=6] [-0.74381445 -0.73506023 -0.73387045]\n",
      "[n=150 d=7] [-0.73686632 -0.73054126 -0.72695325]\n",
      "[n=150 d=8] [-0.73241308 -0.72650992 -0.72194671]\n",
      "[n=150 d=9] [-0.72869813 -0.7253559  -0.71936254]\n",
      "[n=150 d=10] [-0.7261433  -0.72382903 -0.71756249]\n",
      "[n=175 d=2] [-0.79756263 -0.78780425 -0.78675971]\n",
      "[n=175 d=3] [-0.77409994 -0.76321305 -0.76406486]\n",
      "[n=175 d=4] [-0.75812685 -0.74859261 -0.74904275]\n",
      "[n=175 d=5] [-0.74833323 -0.73905011 -0.73892788]\n",
      "[n=175 d=6] [-0.74021541 -0.73137394 -0.72986931]\n",
      "[n=175 d=7] [-0.73389039 -0.72718765 -0.72312794]\n",
      "[n=175 d=8] [-0.72984402 -0.72381259 -0.7190494 ]\n",
      "[n=175 d=9] [-0.72629666 -0.72390999 -0.71741315]\n",
      "[n=175 d=10] [-0.7252497  -0.72362816 -0.71610143]\n",
      "[n=200 d=2] [-0.79181978 -0.78109537 -0.78052508]\n",
      "[n=200 d=3] [-0.76991738 -0.7583127  -0.75924643]\n",
      "[n=200 d=4] [-0.75489877 -0.74509912 -0.74561632]\n",
      "[n=200 d=5] [-0.74546369 -0.73643138 -0.73575741]\n",
      "[n=200 d=6] [-0.7376755  -0.72908079 -0.72693009]\n",
      "[n=200 d=7] [-0.73203077 -0.72559107 -0.72105374]\n",
      "[n=200 d=8] [-0.72814152 -0.7230728  -0.71776156]\n",
      "[n=200 d=9] [-0.72556853 -0.72428678 -0.71633823]\n",
      "[n=200 d=10] [-0.72551751 -0.72420426 -0.71604324]\n",
      "[n=225 d=2] [-0.78715041 -0.77638465 -0.77572456]\n",
      "[n=225 d=3] [-0.76625211 -0.75494134 -0.75571338]\n",
      "[n=225 d=4] [-0.75268358 -0.74274552 -0.74322993]\n",
      "[n=225 d=5] [-0.74337572 -0.73446818 -0.73393474]\n",
      "[n=225 d=6] [-0.73640483 -0.72751617 -0.72568163]\n",
      "[n=225 d=7] [-0.73088851 -0.72427237 -0.71968009]\n",
      "[n=225 d=8] [-0.72760687 -0.72251939 -0.71758837]\n",
      "[n=225 d=9] [-0.72588968 -0.72480193 -0.71724999]\n",
      "[n=225 d=10] [-0.72777108 -0.72559586 -0.71812675]\n",
      "[n=250 d=2] [-0.78375774 -0.77297786 -0.77278296]\n",
      "[n=250 d=3] [-0.76370489 -0.75254232 -0.75397182]\n",
      "[n=250 d=4] [-0.7507899  -0.74124463 -0.74189462]\n",
      "[n=250 d=5] [-0.74142687 -0.732948   -0.73304574]\n",
      "[n=250 d=6] [-0.73516922 -0.72679892 -0.72509985]\n",
      "[n=250 d=7] [-0.73056322 -0.72380704 -0.71899029]\n",
      "[n=250 d=8] [-0.72758765 -0.72300306 -0.71813888]\n",
      "[n=250 d=9] [-0.72795265 -0.72653842 -0.71892591]\n",
      "[n=250 d=10] [-0.72991134 -0.72782463 -0.71982765]\n",
      "[n=275 d=2] [-0.78072666 -0.76984925 -0.76980186]\n",
      "[n=275 d=3] [-0.76163692 -0.75054874 -0.7521134 ]\n",
      "[n=275 d=4] [-0.74944074 -0.73987304 -0.74023361]\n",
      "[n=275 d=5] [-0.74036923 -0.73205392 -0.73188957]\n",
      "[n=275 d=6] [-0.73439057 -0.7266249  -0.72432638]\n",
      "[n=275 d=7] [-0.73046727 -0.72429618 -0.71898574]\n",
      "[n=275 d=8] [-0.72879444 -0.72419324 -0.71839125]\n",
      "[n=275 d=9] [-0.73011144 -0.72888011 -0.72040485]\n",
      "[n=275 d=10] [-0.73340008 -0.73149259 -0.72154237]\n",
      "[n=300 d=2] [-0.77846425 -0.76721675 -0.76760479]\n",
      "[n=300 d=3] [-0.75989581 -0.74913504 -0.75050279]\n",
      "[n=300 d=4] [-0.74835299 -0.73867923 -0.73934803]\n",
      "[n=300 d=5] [-0.73978587 -0.73139115 -0.73149981]\n",
      "[n=300 d=6] [-0.73384486 -0.72690918 -0.72426517]\n",
      "[n=300 d=7] [-0.73050352 -0.72505753 -0.71929776]\n",
      "[n=300 d=8] [-0.72976308 -0.72608948 -0.7202179 ]\n",
      "[n=300 d=9] [-0.73269231 -0.73102337 -0.72356503]\n",
      "[n=300 d=10] [-0.73784637 -0.73502321 -0.72531928]\n",
      "[n=325 d=2] [-0.77644969 -0.76526205 -0.76552055]\n",
      "[n=325 d=3] [-0.75873606 -0.74791471 -0.74889764]\n",
      "[n=325 d=4] [-0.74722909 -0.73795487 -0.73805693]\n",
      "[n=325 d=5] [-0.73892252 -0.73124094 -0.73077793]\n",
      "[n=325 d=6] [-0.7339987  -0.72696658 -0.7242768 ]\n",
      "[n=325 d=7] [-0.73080837 -0.72613723 -0.72013729]\n",
      "[n=325 d=8] [-0.73135059 -0.72805142 -0.72210048]\n",
      "[n=325 d=9] [-0.73476479 -0.73488167 -0.72592491]\n",
      "[n=325 d=10] [-0.740643   -0.73907649 -0.72840815]\n",
      "[n=350 d=2] [-0.77487787 -0.76369705 -0.763767  ]\n",
      "[n=350 d=3] [-0.75776205 -0.74699107 -0.74794722]\n",
      "[n=350 d=4] [-0.74658531 -0.73755365 -0.73731356]\n",
      "[n=350 d=5] [-0.73809199 -0.73140955 -0.73039593]\n",
      "[n=350 d=6] [-0.73372381 -0.72728588 -0.72476608]\n",
      "[n=350 d=7] [-0.73170383 -0.72748311 -0.72057987]\n",
      "[n=350 d=8] [-0.73266303 -0.73057051 -0.72356763]\n",
      "[n=350 d=9] [-0.73776761 -0.73829615 -0.72801471]\n",
      "[n=350 d=10] [-0.74482732 -0.7432453  -0.73160508]\n",
      "[n=375 d=2] [-0.77359944 -0.76209563 -0.76260165]\n",
      "[n=375 d=3] [-0.75680519 -0.74619654 -0.74679421]\n",
      "[n=375 d=4] [-0.74614227 -0.73676842 -0.73678303]\n",
      "[n=375 d=5] [-0.73803401 -0.7309017  -0.72995114]\n",
      "[n=375 d=6] [-0.73447881 -0.72736601 -0.72467357]\n",
      "[n=375 d=7] [-0.73319578 -0.72921738 -0.72173021]\n",
      "[n=375 d=8] [-0.73478913 -0.73276721 -0.7257854 ]\n",
      "[n=375 d=9] [-0.7418203  -0.74185266 -0.73191377]\n",
      "[n=375 d=10] [-0.74894218 -0.74701817 -0.73564166]\n",
      "[n=400 d=2] [-0.77249926 -0.76123828 -0.76154412]\n",
      "[n=400 d=3] [-0.75632401 -0.74548779 -0.74599269]\n",
      "[n=400 d=4] [-0.7458931  -0.73630096 -0.73643068]\n",
      "[n=400 d=5] [-0.73775607 -0.7313196  -0.73016811]\n",
      "[n=400 d=6] [-0.73492405 -0.7282042  -0.72540291]\n",
      "[n=400 d=7] [-0.73386926 -0.73027375 -0.72324433]\n",
      "[n=400 d=8] [-0.73728065 -0.73507056 -0.72797931]\n",
      "[n=400 d=9] [-0.74523072 -0.74493551 -0.73527459]\n",
      "[n=400 d=10] [-0.75339796 -0.75146802 -0.73982688]\n",
      "[n=425 d=2] [-0.77172355 -0.760464   -0.76046386]\n",
      "[n=425 d=3] [-0.75601074 -0.74522705 -0.74534804]\n",
      "[n=425 d=4] [-0.74545696 -0.73623222 -0.73652643]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-73b474d0f10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'[n='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' d='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'] '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    440\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''for n in range(100, 450, 25):\n",
    "    for d in range (2, 11, 1):\n",
    "        clf = xgb.XGBClassifier(max_depth=d, n_estimators=n, learning_rate=0.05, silent=1, objective='multi:softprob',\n",
    "                        subsample=0.55,colsample_bytree=0.65)\n",
    "        fit = clf.fit(data, target)\n",
    "        proba = fit.predict_proba(test)\n",
    "        print '[n='+str(n)+' d='+str(d)+'] '+str(cross_validation.cross_val_score(clf, data, target, scoring='log_loss'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s=0.1 cs=0.1 ] [-0.85059994 -0.86789297 -0.87360959]\n",
      "[s=0.1 cs=0.2 ] [-0.79792914 -0.79916953 -0.81050997]\n",
      "[s=0.1 cs=0.3 ] [-0.77600507 -0.77518143 -0.77586026]\n",
      "[s=0.1 cs=0.4 ] [-0.77177774 -0.76645808 -0.7643714 ]\n",
      "[s=0.1 cs=0.5 ] [-0.76561007 -0.76364174 -0.75793011]\n",
      "[s=0.1 cs=0.6 ] [-0.76379334 -0.75761771 -0.756448  ]\n",
      "[s=0.1 cs=0.7 ] [-0.7665914  -0.76020424 -0.75897846]\n",
      "[s=0.1 cs=0.8 ] [-0.76340055 -0.75880136 -0.75768161]\n",
      "[s=0.1 cs=0.9 ] [-0.76595135 -0.76181241 -0.75397673]\n",
      "[s=0.1 cs=1.0 ] [-0.76775141 -0.76280042 -0.7492964 ]\n",
      "[s=0.2 cs=0.1 ] [-0.84282591 -0.85740493 -0.86487081]\n",
      "[s=0.2 cs=0.2 ] [-0.78432437 -0.78791614 -0.79918766]\n",
      "[s=0.2 cs=0.3 ] [-0.76239168 -0.75864253 -0.7616468 ]\n",
      "[s=0.2 cs=0.4 ] [-0.75378842 -0.74707247 -0.75351368]\n",
      "[s=0.2 cs=0.5 ] [-0.74917764 -0.74368901 -0.74134212]\n",
      "[s=0.2 cs=0.6 ] [-0.74979371 -0.73959749 -0.7344119 ]\n",
      "[s=0.2 cs=0.7 ] [-0.74781278 -0.74017172 -0.73381961]\n",
      "[s=0.2 cs=0.8 ] [-0.74518623 -0.74327911 -0.73690553]\n",
      "[s=0.2 cs=0.9 ] [-0.74736026 -0.73974504 -0.73395807]\n",
      "[s=0.2 cs=1.0 ] [-0.74928233 -0.73983455 -0.73232142]\n",
      "[s=0.3 cs=0.1 ] [-0.83832188 -0.85334118 -0.86011007]\n",
      "[s=0.3 cs=0.2 ] [-0.7784479  -0.7793783  -0.79133974]\n",
      "[s=0.3 cs=0.3 ] [-0.75172748 -0.75204587 -0.75295877]\n",
      "[s=0.3 cs=0.4 ] [-0.74481028 -0.74132878 -0.7415434 ]\n",
      "[s=0.3 cs=0.5 ] [-0.73901294 -0.73548475 -0.73331791]\n",
      "[s=0.3 cs=0.6 ] [-0.74083587 -0.7338261  -0.72799093]\n",
      "[s=0.3 cs=0.7 ] [-0.73980301 -0.73359438 -0.72663298]\n",
      "[s=0.3 cs=0.8 ] [-0.73875678 -0.73497734 -0.72646655]\n",
      "[s=0.3 cs=0.9 ] [-0.73954111 -0.73368777 -0.72619661]\n",
      "[s=0.3 cs=1.0 ] [-0.73919066 -0.73524514 -0.72852344]\n",
      "[s=0.4 cs=0.1 ] [-0.83694537 -0.85103519 -0.858936  ]\n",
      "[s=0.4 cs=0.2 ] [-0.77310039 -0.77544857 -0.78911146]\n",
      "[s=0.4 cs=0.3 ] [-0.7470549  -0.74794902 -0.74804949]\n",
      "[s=0.4 cs=0.4 ] [-0.73959553 -0.736674   -0.73521137]\n",
      "[s=0.4 cs=0.5 ] [-0.73346021 -0.72907189 -0.72789326]\n",
      "[s=0.4 cs=0.6 ] [-0.73349927 -0.72618713 -0.72285593]\n",
      "[s=0.4 cs=0.7 ] [-0.73338391 -0.72597909 -0.72240653]\n",
      "[s=0.4 cs=0.8 ] [-0.73407443 -0.72995438 -0.72188754]\n",
      "[s=0.4 cs=0.9 ] [-0.73303211 -0.72732488 -0.72336992]\n",
      "[s=0.4 cs=1.0 ] [-0.73552185 -0.73149591 -0.7248457 ]\n",
      "[s=0.5 cs=0.1 ] [-0.83518513 -0.84888489 -0.85520874]\n",
      "[s=0.5 cs=0.2 ] [-0.77082537 -0.77314418 -0.78653931]\n",
      "[s=0.5 cs=0.3 ] [-0.74455398 -0.74379957 -0.74516285]\n",
      "[s=0.5 cs=0.4 ] [-0.73253614 -0.73254498 -0.7303866 ]\n",
      "[s=0.5 cs=0.5 ] [-0.72753918 -0.72156501 -0.72322298]\n",
      "[s=0.5 cs=0.6 ] [-0.72647633 -0.72274293 -0.7204062 ]\n",
      "[s=0.5 cs=0.7 ] [-0.72555998 -0.72218515 -0.71907141]\n",
      "[s=0.5 cs=0.8 ] [-0.72748924 -0.72536394 -0.71923583]\n",
      "[s=0.5 cs=0.9 ] [-0.73117179 -0.72566732 -0.72008822]\n",
      "[s=0.5 cs=1.0 ] [-0.73367649 -0.72886758 -0.71859455]\n",
      "[s=0.6 cs=0.1 ] [-0.83469333 -0.84699073 -0.85415452]\n",
      "[s=0.6 cs=0.2 ] [-0.76988221 -0.7719638  -0.78258147]\n",
      "[s=0.6 cs=0.3 ] [-0.74249422 -0.74211001 -0.74503445]\n",
      "[s=0.6 cs=0.4 ] [-0.73062    -0.7293448  -0.72881152]\n",
      "[s=0.6 cs=0.5 ] [-0.72629406 -0.71881478 -0.71948866]\n",
      "[s=0.6 cs=0.6 ] [-0.7259535  -0.72082312 -0.71645336]\n",
      "[s=0.6 cs=0.7 ] [-0.72529563 -0.72073922 -0.71491522]\n",
      "[s=0.6 cs=0.8 ] [-0.72850839 -0.72311095 -0.71563765]\n",
      "[s=0.6 cs=0.9 ] [-0.72869578 -0.72387505 -0.71501365]\n",
      "[s=0.6 cs=1.0 ] [-0.73447639 -0.72605678 -0.71929824]\n",
      "[s=0.7 cs=0.1 ] [-0.8331074  -0.84602393 -0.8537492 ]\n",
      "[s=0.7 cs=0.2 ] [-0.76994561 -0.76960627 -0.78107053]\n",
      "[s=0.7 cs=0.3 ] [-0.73812117 -0.73919916 -0.73980246]\n",
      "[s=0.7 cs=0.4 ] [-0.73211471 -0.72591444 -0.72502076]\n",
      "[s=0.7 cs=0.5 ] [-0.72664838 -0.71916641 -0.71679897]\n",
      "[s=0.7 cs=0.6 ] [-0.72403146 -0.71894631 -0.7143648 ]\n",
      "[s=0.7 cs=0.7 ] [-0.72382486 -0.71680502 -0.7155742 ]\n",
      "[s=0.7 cs=0.8 ] [-0.73063392 -0.72036014 -0.71471116]\n",
      "[s=0.7 cs=0.9 ] [-0.73149714 -0.72246152 -0.71438468]\n",
      "[s=0.7 cs=1.0 ] [-0.73288023 -0.72458109 -0.71539869]\n",
      "[s=0.8 cs=0.1 ] [-0.83316851 -0.84405575 -0.85222634]\n",
      "[s=0.8 cs=0.2 ] [-0.76710502 -0.769883   -0.78022332]\n",
      "[s=0.8 cs=0.3 ] [-0.73751027 -0.73796055 -0.73917727]\n",
      "[s=0.8 cs=0.4 ] [-0.73021275 -0.72652679 -0.72393954]\n",
      "[s=0.8 cs=0.5 ] [-0.72361002 -0.72028333 -0.71460286]\n",
      "[s=0.8 cs=0.6 ] [-0.72246914 -0.71717815 -0.7130527 ]\n",
      "[s=0.8 cs=0.7 ] [-0.72297742 -0.71966538 -0.71311044]\n",
      "[s=0.8 cs=0.8 ] [-0.72981999 -0.72294819 -0.71447869]\n",
      "[s=0.8 cs=0.9 ] [-0.73221362 -0.72320838 -0.71568072]\n",
      "[s=0.8 cs=1.0 ] [-0.73766472 -0.72882589 -0.71931758]\n",
      "[s=0.9 cs=0.1 ] [-0.83251637 -0.8437293  -0.85162118]\n",
      "[s=0.9 cs=0.2 ] [-0.7654939  -0.76679004 -0.77784803]\n",
      "[s=0.9 cs=0.3 ] [-0.73958647 -0.73682817 -0.73797094]\n",
      "[s=0.9 cs=0.4 ] [-0.73014912 -0.72668787 -0.72282706]\n",
      "[s=0.9 cs=0.5 ] [-0.72403605 -0.72028732 -0.7162414 ]\n",
      "[s=0.9 cs=0.6 ] [-0.72461985 -0.71874956 -0.71206392]\n",
      "[s=0.9 cs=0.7 ] [-0.72514552 -0.7210036  -0.71260991]\n",
      "[s=0.9 cs=0.8 ] [-0.72986267 -0.72489055 -0.71302069]\n",
      "[s=0.9 cs=0.9 ] [-0.73243593 -0.72758185 -0.71866285]\n",
      "[s=0.9 cs=1.0 ] [-0.73845224 -0.73450699 -0.72090941]\n",
      "[s=1.0 cs=0.1 ] [-0.85564524 -0.85265514 -0.85142402]\n",
      "[s=1.0 cs=0.2 ] [-0.7801808  -0.7779874  -0.77670227]\n",
      "[s=1.0 cs=0.3 ] [-0.74087826 -0.73690377 -0.73340889]\n",
      "[s=1.0 cs=0.4 ] [-0.73167214 -0.72576007 -0.72180213]\n",
      "[s=1.0 cs=0.5 ] [-0.72602248 -0.72144724 -0.71553807]\n",
      "[s=1.0 cs=0.6 ] [-0.7265185  -0.71974228 -0.71322202]\n",
      "[s=1.0 cs=0.7 ] [-0.72985964 -0.7231855  -0.71401383]\n",
      "[s=1.0 cs=0.8 ] [-0.73470614 -0.73044859 -0.72035776]\n",
      "[s=1.0 cs=0.9 ] [-0.74139629 -0.73555184 -0.7239893 ]\n",
      "[s=1.0 cs=1.0 ] [-0.75092369 -0.74994373 -0.73638268]\n"
     ]
    }
   ],
   "source": [
    "for s in np.arange(0.1,1.1,0.1):\n",
    "    for cs in np.arange(0.1,1.1,0.1):\n",
    "        clf = xgb.XGBClassifier(max_depth=11, n_estimators=175, learning_rate=0.05, silent=1, objective='multi:softprob',\n",
    "                subsample=s,colsample_bytree=cs)\n",
    "        fit = clf.fit(data, target)\n",
    "        proba = fit.predict_proba(test)\n",
    "        print '[s='+str(s)+' cs='+str(cs)+' ] '+str(cross_validation.cross_val_score(clf, data, target, scoring='log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n=100 d=2 s=0.1 cs=0.1 ] [-0.94534237 -0.96615564 -0.97205961]\n",
      "[n=100 d=2 s=0.1 cs=0.2 ] [-0.89361056 -0.89774932 -0.91105061]\n",
      "[n=100 d=2 s=0.1 cs=0.3 ] [-0.86447794 -0.86553837 -0.86306399]\n",
      "[n=100 d=2 s=0.1 cs=0.4 ] [-0.85441426 -0.85213858 -0.84432649]\n",
      "[n=100 d=2 s=0.1 cs=0.5 ] [-0.84680554 -0.84012014 -0.83340618]\n",
      "[n=100 d=2 s=0.1 cs=0.6 ] [-0.84241978 -0.83477122 -0.83022574]\n",
      "[n=100 d=2 s=0.1 cs=0.7 ] [-0.83932105 -0.82984744 -0.82655684]\n",
      "[n=100 d=2 s=0.1 cs=0.8 ] [-0.83714527 -0.82821988 -0.82467509]\n",
      "[n=100 d=2 s=0.1 cs=0.9 ] [-0.8354839  -0.82554629 -0.82223663]\n",
      "[n=100 d=2 s=0.1 cs=1.0 ] [-0.83328082 -0.82386405 -0.82168291]\n",
      "[n=100 d=2 s=0.2 cs=0.1 ] [-0.94357163 -0.96366755 -0.97043543]\n",
      "[n=100 d=2 s=0.2 cs=0.2 ] [-0.89140468 -0.89690358 -0.90727858]\n",
      "[n=100 d=2 s=0.2 cs=0.3 ] [-0.86207569 -0.86323861 -0.85972949]\n",
      "[n=100 d=2 s=0.2 cs=0.4 ] [-0.85034292 -0.84887386 -0.84271728]\n",
      "[n=100 d=2 s=0.2 cs=0.5 ] [-0.84087624 -0.83642504 -0.831777  ]\n",
      "[n=100 d=2 s=0.2 cs=0.6 ] [-0.83837419 -0.82987087 -0.82734684]\n",
      "[n=100 d=2 s=0.2 cs=0.7 ] [-0.83588246 -0.82683938 -0.82199662]\n",
      "[n=100 d=2 s=0.2 cs=0.8 ] [-0.83508306 -0.82472596 -0.81954708]\n",
      "[n=100 d=2 s=0.2 cs=0.9 ] [-0.8327385  -0.82284015 -0.81862757]\n",
      "[n=100 d=2 s=0.2 cs=1.0 ] [-0.83116811 -0.82161027 -0.81745386]\n",
      "[n=100 d=2 s=0.3 cs=0.1 ] [-0.94345398 -0.96320264 -0.97033639]\n",
      "[n=100 d=2 s=0.3 cs=0.2 ] [-0.8899112  -0.89536214 -0.90687607]\n",
      "[n=100 d=2 s=0.3 cs=0.3 ] [-0.86003518 -0.86239435 -0.85910028]\n",
      "[n=100 d=2 s=0.3 cs=0.4 ] [-0.85089798 -0.84752811 -0.84162688]\n",
      "[n=100 d=2 s=0.3 cs=0.5 ] [-0.8411279  -0.83597156 -0.83100038]\n",
      "[n=100 d=2 s=0.3 cs=0.6 ] [-0.83778963 -0.82928797 -0.82581221]\n",
      "[n=100 d=2 s=0.3 cs=0.7 ] [-0.83504005 -0.82636831 -0.8216169 ]\n",
      "[n=100 d=2 s=0.3 cs=0.8 ] [-0.83423603 -0.82460989 -0.81944508]\n",
      "[n=100 d=2 s=0.3 cs=0.9 ] [-0.83259649 -0.82274782 -0.81743789]\n",
      "[n=100 d=2 s=0.3 cs=1.0 ] [-0.83025229 -0.82111433 -0.81699469]\n",
      "[n=100 d=2 s=0.4 cs=0.1 ] [-0.94378385 -0.9640811  -0.97017287]\n",
      "[n=100 d=2 s=0.4 cs=0.2 ] [-0.88895278 -0.89555236 -0.90696403]\n",
      "[n=100 d=2 s=0.4 cs=0.3 ] [-0.85975885 -0.86166601 -0.85887528]\n",
      "[n=100 d=2 s=0.4 cs=0.4 ] [-0.84930769 -0.84710482 -0.84172855]\n",
      "[n=100 d=2 s=0.4 cs=0.5 ] [-0.84085102 -0.83533288 -0.83018696]\n",
      "[n=100 d=2 s=0.4 cs=0.6 ] [-0.8375478  -0.82914169 -0.82560419]\n",
      "[n=100 d=2 s=0.4 cs=0.7 ] [-0.83488231 -0.82607135 -0.82117508]\n",
      "[n=100 d=2 s=0.4 cs=0.8 ] [-0.83404009 -0.82499806 -0.81977872]\n",
      "[n=100 d=2 s=0.4 cs=0.9 ] [-0.83188668 -0.82300135 -0.81903363]\n",
      "[n=100 d=2 s=0.4 cs=1.0 ] [-0.83061399 -0.82223984 -0.81778098]\n",
      "[n=100 d=2 s=0.5 cs=0.1 ] [-0.94336446 -0.96422814 -0.96983389]\n",
      "[n=100 d=2 s=0.5 cs=0.2 ] [-0.88893886 -0.89571562 -0.90664937]\n",
      "[n=100 d=2 s=0.5 cs=0.3 ] [-0.85921051 -0.86206524 -0.85832956]\n",
      "[n=100 d=2 s=0.5 cs=0.4 ] [-0.84849869 -0.84701041 -0.84193211]\n",
      "[n=100 d=2 s=0.5 cs=0.5 ] [-0.84048349 -0.83584576 -0.83034911]\n",
      "[n=100 d=2 s=0.5 cs=0.6 ] [-0.83738359 -0.82951903 -0.8253392 ]\n",
      "[n=100 d=2 s=0.5 cs=0.7 ] [-0.83506191 -0.82692174 -0.82160393]\n",
      "[n=100 d=2 s=0.5 cs=0.8 ] [-0.8342824  -0.82522412 -0.81996726]\n",
      "[n=100 d=2 s=0.5 cs=0.9 ] [-0.8323696  -0.82435927 -0.81934824]\n",
      "[n=100 d=2 s=0.5 cs=1.0 ] [-0.83152304 -0.82324991 -0.81827034]\n",
      "[n=100 d=2 s=0.6 cs=0.1 ] [-0.94332874 -0.96387017 -0.96958063]\n",
      "[n=100 d=2 s=0.6 cs=0.2 ] [-0.88834167 -0.89576338 -0.90632518]\n",
      "[n=100 d=2 s=0.6 cs=0.3 ] [-0.85864169 -0.86222625 -0.85832432]\n",
      "[n=100 d=2 s=0.6 cs=0.4 ] [-0.84850233 -0.84733476 -0.84168654]\n",
      "[n=100 d=2 s=0.6 cs=0.5 ] [-0.83975333 -0.83604271 -0.83006193]\n",
      "[n=100 d=2 s=0.6 cs=0.6 ] [-0.83644101 -0.82955214 -0.82539349]\n",
      "[n=100 d=2 s=0.6 cs=0.7 ] [-0.83443604 -0.82692752 -0.82153441]\n",
      "[n=100 d=2 s=0.6 cs=0.8 ] [-0.83377792 -0.82514816 -0.82049444]\n",
      "[n=100 d=2 s=0.6 cs=0.9 ] [-0.83244703 -0.82441229 -0.81981559]\n",
      "[n=100 d=2 s=0.6 cs=1.0 ] [-0.83099255 -0.82343037 -0.81833024]\n",
      "[n=100 d=2 s=0.7 cs=0.1 ] [-0.9431636  -0.96336768 -0.96952876]\n",
      "[n=100 d=2 s=0.7 cs=0.2 ] [-0.88847473 -0.89576413 -0.90682361]\n",
      "[n=100 d=2 s=0.7 cs=0.3 ] [-0.8583217  -0.86208092 -0.85817034]\n",
      "[n=100 d=2 s=0.7 cs=0.4 ] [-0.84834126 -0.84725832 -0.84204552]\n",
      "[n=100 d=2 s=0.7 cs=0.5 ] [-0.84032369 -0.83626341 -0.83085326]\n",
      "[n=100 d=2 s=0.7 cs=0.6 ] [-0.83676311 -0.82999497 -0.82616109]\n",
      "[n=100 d=2 s=0.7 cs=0.7 ] [-0.83444597 -0.82714682 -0.82204068]\n",
      "[n=100 d=2 s=0.7 cs=0.8 ] [-0.83453507 -0.82608848 -0.82125002]\n",
      "[n=100 d=2 s=0.7 cs=0.9 ] [-0.83316552 -0.82488839 -0.82001782]\n",
      "[n=100 d=2 s=0.7 cs=1.0 ] [-0.83152051 -0.82392739 -0.81926233]\n",
      "[n=100 d=2 s=0.8 cs=0.1 ] [-0.9430071  -0.96338087 -0.96962386]\n",
      "[n=100 d=2 s=0.8 cs=0.2 ] [-0.88897038 -0.89609812 -0.90724388]\n",
      "[n=100 d=2 s=0.8 cs=0.3 ] [-0.8586035  -0.86167555 -0.8585998 ]\n",
      "[n=100 d=2 s=0.8 cs=0.4 ] [-0.8483546 -0.8470243 -0.8419792]\n",
      "[n=100 d=2 s=0.8 cs=0.5 ] [-0.84007164 -0.8357594  -0.83087651]\n",
      "[n=100 d=2 s=0.8 cs=0.6 ] [-0.83671091 -0.82990749 -0.82575681]\n",
      "[n=100 d=2 s=0.8 cs=0.7 ] [-0.8349663  -0.82760958 -0.82225574]\n",
      "[n=100 d=2 s=0.8 cs=0.8 ] [-0.83443236 -0.82668121 -0.82197347]\n",
      "[n=100 d=2 s=0.8 cs=0.9 ] [-0.83337298 -0.82569839 -0.82121736]\n",
      "[n=100 d=2 s=0.8 cs=1.0 ] [-0.83184112 -0.82469549 -0.81972577]\n",
      "[n=100 d=2 s=0.9 cs=0.1 ] [-0.94276461 -0.96325396 -0.96947084]\n",
      "[n=100 d=2 s=0.9 cs=0.2 ] [-0.88783815 -0.89609608 -0.90700751]\n",
      "[n=100 d=2 s=0.9 cs=0.3 ] [-0.85853067 -0.8618316  -0.85858367]\n",
      "[n=100 d=2 s=0.9 cs=0.4 ] [-0.84840325 -0.84706673 -0.84235712]\n",
      "[n=100 d=2 s=0.9 cs=0.5 ] [-0.8402275  -0.8357978  -0.83107294]\n",
      "[n=100 d=2 s=0.9 cs=0.6 ] [-0.83688022 -0.82960406 -0.82646768]\n",
      "[n=100 d=2 s=0.9 cs=0.7 ] [-0.83468968 -0.82713698 -0.82312275]\n",
      "[n=100 d=2 s=0.9 cs=0.8 ] [-0.83450902 -0.82672972 -0.82233496]\n",
      "[n=100 d=2 s=0.9 cs=0.9 ] [-0.83323917 -0.82584474 -0.82155056]\n",
      "[n=100 d=2 s=0.9 cs=1.0 ] [-0.83254497 -0.82499942 -0.82083614]\n",
      "[n=100 d=2 s=1.0 cs=0.1 ] [-0.9716575  -0.96813667 -0.96808193]\n",
      "[n=100 d=2 s=1.0 cs=0.2 ] [-0.90890546 -0.90387855 -0.90367119]\n",
      "[n=100 d=2 s=1.0 cs=0.3 ] [-0.86635652 -0.85984772 -0.85800644]\n",
      "[n=100 d=2 s=1.0 cs=0.4 ] [-0.85251332 -0.84593418 -0.84319258]\n",
      "[n=100 d=2 s=1.0 cs=0.5 ] [-0.84220048 -0.83538327 -0.8323524 ]\n",
      "[n=100 d=2 s=1.0 cs=0.6 ] [-0.83881325 -0.83224815 -0.82840283]\n",
      "[n=100 d=2 s=1.0 cs=0.7 ] [-0.83611397 -0.8292435  -0.82504411]\n",
      "[n=100 d=2 s=1.0 cs=0.8 ] [-0.83401067 -0.82767451 -0.82262793]\n",
      "[n=100 d=2 s=1.0 cs=0.9 ] [-0.83296925 -0.82695214 -0.82202942]\n",
      "[n=100 d=2 s=1.0 cs=1.0 ] [-0.83307063 -0.82575646 -0.82194473]\n",
      "[n=100 d=3 s=0.1 cs=0.1 ] [-0.93177751 -0.95371659 -0.95951043]\n",
      "[n=100 d=3 s=0.1 cs=0.2 ] [-0.87478919 -0.88000905 -0.89330577]\n",
      "[n=100 d=3 s=0.1 cs=0.3 ] [-0.84223911 -0.84347636 -0.84360208]\n",
      "[n=100 d=3 s=0.1 cs=0.4 ] [-0.83150119 -0.82712125 -0.82214434]\n",
      "[n=100 d=3 s=0.1 cs=0.5 ] [-0.82344176 -0.8154222  -0.81164996]\n",
      "[n=100 d=3 s=0.1 cs=0.6 ] [-0.81939279 -0.80911549 -0.80655802]\n",
      "[n=100 d=3 s=0.1 cs=0.7 ] [-0.81604596 -0.80489817 -0.80164512]\n",
      "[n=100 d=3 s=0.1 cs=0.8 ] [-0.81347192 -0.80159489 -0.79820467]\n",
      "[n=100 d=3 s=0.1 cs=0.9 ] [-0.81171733 -0.80002489 -0.79751317]\n",
      "[n=100 d=3 s=0.1 cs=1.0 ] [-0.81067449 -0.79776214 -0.7968768 ]\n",
      "[n=100 d=3 s=0.2 cs=0.1 ] [-0.92876196 -0.95001112 -0.95704856]\n",
      "[n=100 d=3 s=0.2 cs=0.2 ] [-0.87050965 -0.87613429 -0.888623  ]\n",
      "[n=100 d=3 s=0.2 cs=0.3 ] [-0.83738289 -0.8387609  -0.83824386]\n",
      "[n=100 d=3 s=0.2 cs=0.4 ] [-0.82550067 -0.82252345 -0.81782718]\n",
      "[n=100 d=3 s=0.2 cs=0.5 ] [-0.81538383 -0.8093048  -0.80582619]\n",
      "[n=100 d=3 s=0.2 cs=0.6 ] [-0.81085782 -0.80130171 -0.79944076]\n",
      "[n=100 d=3 s=0.2 cs=0.7 ] [-0.80810498 -0.79853518 -0.79494814]\n",
      "[n=100 d=3 s=0.2 cs=0.8 ] [-0.80567681 -0.79609487 -0.79226846]\n",
      "[n=100 d=3 s=0.2 cs=0.9 ] [-0.80422166 -0.79425294 -0.79093118]\n",
      "[n=100 d=3 s=0.2 cs=1.0 ] [-0.80363183 -0.79239615 -0.78985229]\n",
      "[n=100 d=3 s=0.3 cs=0.1 ] [-0.92764106 -0.94850215 -0.95508315]\n",
      "[n=100 d=3 s=0.3 cs=0.2 ] [-0.8689876  -0.87489689 -0.88680797]\n",
      "[n=100 d=3 s=0.3 cs=0.3 ] [-0.83466261 -0.83706781 -0.83641603]\n",
      "[n=100 d=3 s=0.3 cs=0.4 ] [-0.82291157 -0.81996229 -0.81610951]\n",
      "[n=100 d=3 s=0.3 cs=0.5 ] [-0.81264855 -0.80617993 -0.8035105 ]\n",
      "[n=100 d=3 s=0.3 cs=0.6 ] [-0.80865075 -0.7998001  -0.79739154]\n",
      "[n=100 d=3 s=0.3 cs=0.7 ] [-0.80582431 -0.79600153 -0.79269394]\n",
      "[n=100 d=3 s=0.3 cs=0.8 ] [-0.80486864 -0.79343927 -0.79069908]\n",
      "[n=100 d=3 s=0.3 cs=0.9 ] [-0.8025991  -0.79206716 -0.78963046]\n",
      "[n=100 d=3 s=0.3 cs=1.0 ] [-0.80123532 -0.79119203 -0.78894983]\n",
      "[n=100 d=3 s=0.4 cs=0.1 ] [-0.92802591 -0.94822536 -0.95529481]\n",
      "[n=100 d=3 s=0.4 cs=0.2 ] [-0.86800862 -0.87404116 -0.88681998]\n",
      "[n=100 d=3 s=0.4 cs=0.3 ] [-0.83346057 -0.83619424 -0.83517247]\n",
      "[n=100 d=3 s=0.4 cs=0.4 ] [-0.82156978 -0.8194109  -0.81477878]\n",
      "[n=100 d=3 s=0.4 cs=0.5 ] [-0.81261609 -0.80535458 -0.80308773]\n",
      "[n=100 d=3 s=0.4 cs=0.6 ] [-0.8074603  -0.79856311 -0.79733146]\n",
      "[n=100 d=3 s=0.4 cs=0.7 ] [-0.80462529 -0.79498404 -0.79265422]\n",
      "[n=100 d=3 s=0.4 cs=0.8 ] [-0.80352211 -0.79295818 -0.7904646 ]\n",
      "[n=100 d=3 s=0.4 cs=0.9 ] [-0.80142636 -0.79139292 -0.78904528]\n",
      "[n=100 d=3 s=0.4 cs=1.0 ] [-0.80101932 -0.79043309 -0.78809348]\n",
      "[n=100 d=3 s=0.5 cs=0.1 ] [-0.92710093 -0.94881001 -0.95471591]\n",
      "[n=100 d=3 s=0.5 cs=0.2 ] [-0.86733952 -0.87370526 -0.88594789]\n",
      "[n=100 d=3 s=0.5 cs=0.3 ] [-0.83245921 -0.83570177 -0.83470481]\n",
      "[n=100 d=3 s=0.5 cs=0.4 ] [-0.82083906 -0.81878888 -0.81510702]\n",
      "[n=100 d=3 s=0.5 cs=0.5 ] [-0.81178284 -0.8053438  -0.80343292]\n",
      "[n=100 d=3 s=0.5 cs=0.6 ] [-0.80687687 -0.79888686 -0.7970591 ]\n",
      "[n=100 d=3 s=0.5 cs=0.7 ] [-0.80403389 -0.79471813 -0.79256329]\n",
      "[n=100 d=3 s=0.5 cs=0.8 ] [-0.80342564 -0.79249274 -0.79047766]\n",
      "[n=100 d=3 s=0.5 cs=0.9 ] [-0.80190767 -0.79145745 -0.78933937]\n",
      "[n=100 d=3 s=0.5 cs=1.0 ] [-0.80122119 -0.79094087 -0.78843346]\n",
      "[n=100 d=3 s=0.6 cs=0.1 ] [-0.92698266 -0.94863388 -0.95452635]\n",
      "[n=100 d=3 s=0.6 cs=0.2 ] [-0.86705417 -0.87339782 -0.88573352]\n",
      "[n=100 d=3 s=0.6 cs=0.3 ] [-0.83247762 -0.83553391 -0.83449326]\n",
      "[n=100 d=3 s=0.6 cs=0.4 ] [-0.82063666 -0.81843317 -0.81429395]\n",
      "[n=100 d=3 s=0.6 cs=0.5 ] [-0.81138263 -0.80514299 -0.80328207]\n",
      "[n=100 d=3 s=0.6 cs=0.6 ] [-0.80725558 -0.7987038  -0.79741306]\n",
      "[n=100 d=3 s=0.6 cs=0.7 ] [-0.80399794 -0.79498274 -0.79341364]\n",
      "[n=100 d=3 s=0.6 cs=0.8 ] [-0.8028841  -0.79294991 -0.79115844]\n",
      "[n=100 d=3 s=0.6 cs=0.9 ] [-0.80233365 -0.79178677 -0.7898895 ]\n",
      "[n=100 d=3 s=0.6 cs=1.0 ] [-0.80111155 -0.79082637 -0.78899307]\n",
      "[n=100 d=3 s=0.7 cs=0.1 ] [-0.92718429 -0.94846089 -0.95408648]\n",
      "[n=100 d=3 s=0.7 cs=0.2 ] [-0.86687316 -0.87368595 -0.8855521 ]\n",
      "[n=100 d=3 s=0.7 cs=0.3 ] [-0.83219022 -0.83512744 -0.83427666]\n",
      "[n=100 d=3 s=0.7 cs=0.4 ] [-0.82044724 -0.8183066  -0.81503946]\n",
      "[n=100 d=3 s=0.7 cs=0.5 ] [-0.81115539 -0.80543789 -0.80335088]\n",
      "[n=100 d=3 s=0.7 cs=0.6 ] [-0.80701842 -0.79854274 -0.79734253]\n",
      "[n=100 d=3 s=0.7 cs=0.7 ] [-0.804125   -0.79469185 -0.79384214]\n",
      "[n=100 d=3 s=0.7 cs=0.8 ] [-0.80368506 -0.79252864 -0.79140441]\n",
      "[n=100 d=3 s=0.7 cs=0.9 ] [-0.80214112 -0.79232193 -0.7901202 ]\n",
      "[n=100 d=3 s=0.7 cs=1.0 ] [-0.80146322 -0.79168301 -0.78966929]\n",
      "[n=100 d=3 s=0.8 cs=0.1 ] [-0.92676792 -0.94838128 -0.95375155]\n",
      "[n=100 d=3 s=0.8 cs=0.2 ] [-0.86678081 -0.87343245 -0.88513027]\n",
      "[n=100 d=3 s=0.8 cs=0.3 ] [-0.83225121 -0.83460051 -0.83389785]\n",
      "[n=100 d=3 s=0.8 cs=0.4 ] [-0.82014692 -0.81835949 -0.81499388]\n",
      "[n=100 d=3 s=0.8 cs=0.5 ] [-0.81129458 -0.80537494 -0.80274417]\n",
      "[n=100 d=3 s=0.8 cs=0.6 ] [-0.8062143  -0.79818684 -0.79700243]\n",
      "[n=100 d=3 s=0.8 cs=0.7 ] [-0.80371856 -0.79556145 -0.79375726]\n",
      "[n=100 d=3 s=0.8 cs=0.8 ] [-0.80252282 -0.79289333 -0.79245159]\n",
      "[n=100 d=3 s=0.8 cs=0.9 ] [-0.8019769  -0.79252736 -0.79106098]\n",
      "[n=100 d=3 s=0.8 cs=1.0 ] [-0.8012915  -0.79218049 -0.79067707]\n",
      "[n=100 d=3 s=0.9 cs=0.1 ] [-0.92662359 -0.94818628 -0.9539303 ]\n",
      "[n=100 d=3 s=0.9 cs=0.2 ] [-0.8665388  -0.87314723 -0.88512473]\n",
      "[n=100 d=3 s=0.9 cs=0.3 ] [-0.83206908 -0.83476098 -0.83380902]\n",
      "[n=100 d=3 s=0.9 cs=0.4 ] [-0.82007371 -0.81797625 -0.81518689]\n",
      "[n=100 d=3 s=0.9 cs=0.5 ] [-0.81078305 -0.80527322 -0.80314136]\n",
      "[n=100 d=3 s=0.9 cs=0.6 ] [-0.80637089 -0.79786439 -0.79762297]\n",
      "[n=100 d=3 s=0.9 cs=0.7 ] [-0.80388    -0.79537074 -0.793903  ]\n",
      "[n=100 d=3 s=0.9 cs=0.8 ] [-0.80250321 -0.79315388 -0.79222755]\n",
      "[n=100 d=3 s=0.9 cs=0.9 ] [-0.8021699  -0.79342629 -0.79170054]\n",
      "[n=100 d=3 s=0.9 cs=1.0 ] [-0.80160398 -0.792857   -0.79145504]\n",
      "[n=100 d=3 s=1.0 cs=0.1 ] [-0.95443382 -0.95135778 -0.95131103]\n",
      "[n=100 d=3 s=1.0 cs=0.2 ] [-0.88603691 -0.88000908 -0.88093385]\n",
      "[n=100 d=3 s=1.0 cs=0.3 ] [-0.84024784 -0.83236676 -0.832309  ]\n",
      "[n=100 d=3 s=1.0 cs=0.4 ] [-0.82479088 -0.81813998 -0.81683352]\n",
      "[n=100 d=3 s=1.0 cs=0.5 ] [-0.81317361 -0.80571111 -0.80403692]\n",
      "[n=100 d=3 s=1.0 cs=0.6 ] [-0.80887712 -0.80086593 -0.79936396]\n",
      "[n=100 d=3 s=1.0 cs=0.7 ] [-0.80530017 -0.79628243 -0.7945872 ]\n",
      "[n=100 d=3 s=1.0 cs=0.8 ] [-0.80357274 -0.7945336  -0.79252847]\n",
      "[n=100 d=3 s=1.0 cs=0.9 ] [-0.80216056 -0.79368631 -0.79195621]\n",
      "[n=100 d=3 s=1.0 cs=1.0 ] [-0.80213179 -0.79407749 -0.79278512]\n",
      "[n=100 d=4 s=0.1 cs=0.1 ] [-0.92418507 -0.94719715 -0.95139614]\n",
      "[n=100 d=4 s=0.1 cs=0.2 ] [-0.86504905 -0.87074739 -0.88367283]\n",
      "[n=100 d=4 s=0.1 cs=0.3 ] [-0.83049281 -0.8316237  -0.83266779]\n",
      "[n=100 d=4 s=0.1 cs=0.4 ] [-0.81940654 -0.81360858 -0.81102253]\n",
      "[n=100 d=4 s=0.1 cs=0.5 ] [-0.8097235  -0.80096594 -0.7991891 ]\n",
      "[n=100 d=4 s=0.1 cs=0.6 ] [-0.80309394 -0.79507249 -0.79280141]\n",
      "[n=100 d=4 s=0.1 cs=0.7 ] [-0.80103712 -0.7909096  -0.78854852]\n",
      "[n=100 d=4 s=0.1 cs=0.8 ] [-0.79763938 -0.78740643 -0.78479321]\n",
      "[n=100 d=4 s=0.1 cs=0.9 ] [-0.79637247 -0.78435121 -0.78238089]\n",
      "[n=100 d=4 s=0.1 cs=1.0 ] [-0.79654995 -0.78199055 -0.78100625]\n",
      "[n=100 d=4 s=0.2 cs=0.1 ] [-0.92026713 -0.94170953 -0.94782863]\n",
      "[n=100 d=4 s=0.2 cs=0.2 ] [-0.85822238 -0.86431691 -0.8778227 ]\n",
      "[n=100 d=4 s=0.2 cs=0.3 ] [-0.82337699 -0.82574094 -0.82430998]\n",
      "[n=100 d=4 s=0.2 cs=0.4 ] [-0.81045416 -0.80655667 -0.80313278]\n",
      "[n=100 d=4 s=0.2 cs=0.5 ] [-0.79889189 -0.79267109 -0.7903494 ]\n",
      "[n=100 d=4 s=0.2 cs=0.6 ] [-0.79367702 -0.78458152 -0.78361937]\n",
      "[n=100 d=4 s=0.2 cs=0.7 ] [-0.79027219 -0.78096127 -0.77831102]\n",
      "[n=100 d=4 s=0.2 cs=0.8 ] [-0.7889461  -0.7791085  -0.77457185]\n",
      "[n=100 d=4 s=0.2 cs=0.9 ] [-0.78684242 -0.77715565 -0.77363211]\n",
      "[n=100 d=4 s=0.2 cs=1.0 ] [-0.78638034 -0.77492653 -0.77410436]\n",
      "[n=100 d=4 s=0.3 cs=0.1 ] [-0.91920501 -0.94006984 -0.94551384]\n",
      "[n=100 d=4 s=0.3 cs=0.2 ] [-0.85533348 -0.86131396 -0.87469516]\n",
      "[n=100 d=4 s=0.3 cs=0.3 ] [-0.81896479 -0.82232695 -0.82284297]\n",
      "[n=100 d=4 s=0.3 cs=0.4 ] [-0.80592635 -0.80333155 -0.80006355]\n",
      "[n=100 d=4 s=0.3 cs=0.5 ] [-0.79485297 -0.79013017 -0.78722128]\n",
      "[n=100 d=4 s=0.3 cs=0.6 ] [-0.79076624 -0.78237135 -0.78072009]\n",
      "[n=100 d=4 s=0.3 cs=0.7 ] [-0.78695908 -0.77803002 -0.77515806]\n",
      "[n=100 d=4 s=0.3 cs=0.8 ] [-0.78533516 -0.77434372 -0.77362035]\n",
      "[n=100 d=4 s=0.3 cs=0.9 ] [-0.78441869 -0.77384671 -0.77131807]\n",
      "[n=100 d=4 s=0.3 cs=1.0 ] [-0.78301464 -0.7732447  -0.77094384]\n",
      "[n=100 d=4 s=0.4 cs=0.1 ] [-0.91816589 -0.93881721 -0.94572072]\n",
      "[n=100 d=4 s=0.4 cs=0.2 ] [-0.85384008 -0.85966381 -0.87441744]\n",
      "[n=100 d=4 s=0.4 cs=0.3 ] [-0.81754381 -0.81983139 -0.82004706]\n",
      "[n=100 d=4 s=0.4 cs=0.4 ] [-0.80402842 -0.80213239 -0.7990353 ]\n",
      "[n=100 d=4 s=0.4 cs=0.5 ] [-0.79374969 -0.78785951 -0.78616288]\n",
      "[n=100 d=4 s=0.4 cs=0.6 ] [-0.78816116 -0.77963152 -0.78019481]\n",
      "[n=100 d=4 s=0.4 cs=0.7 ] [-0.78485571 -0.77590596 -0.77534257]\n",
      "[n=100 d=4 s=0.4 cs=0.8 ] [-0.78405788 -0.77309216 -0.77305183]\n",
      "[n=100 d=4 s=0.4 cs=0.9 ] [-0.78257782 -0.77136957 -0.77106676]\n",
      "[n=100 d=4 s=0.4 cs=1.0 ] [-0.78232224 -0.7708782  -0.76914009]\n",
      "[n=100 d=4 s=0.5 cs=0.1 ] [-0.91775606 -0.9384951  -0.94554241]\n",
      "[n=100 d=4 s=0.5 cs=0.2 ] [-0.85259344 -0.8592255  -0.87346433]\n",
      "[n=100 d=4 s=0.5 cs=0.3 ] [-0.81586188 -0.81960279 -0.82005895]\n",
      "[n=100 d=4 s=0.5 cs=0.4 ] [-0.80296082 -0.80066707 -0.7983809 ]\n",
      "[n=100 d=4 s=0.5 cs=0.5 ] [-0.79306312 -0.78598721 -0.78560472]\n",
      "[n=100 d=4 s=0.5 cs=0.6 ] [-0.78751352 -0.77873589 -0.77870534]\n",
      "[n=100 d=4 s=0.5 cs=0.7 ] [-0.78422946 -0.77504288 -0.77424038]\n",
      "[n=100 d=4 s=0.5 cs=0.8 ] [-0.78354631 -0.77260918 -0.77230304]\n",
      "[n=100 d=4 s=0.5 cs=0.9 ] [-0.78258582 -0.77070184 -0.76989127]\n",
      "[n=100 d=4 s=0.5 cs=1.0 ] [-0.78200793 -0.77009398 -0.76917868]\n",
      "[n=100 d=4 s=0.6 cs=0.1 ] [-0.91722129 -0.93881432 -0.9443287 ]\n",
      "[n=100 d=4 s=0.6 cs=0.2 ] [-0.85252249 -0.85869805 -0.87255653]\n",
      "[n=100 d=4 s=0.6 cs=0.3 ] [-0.8156244  -0.81819629 -0.81796004]\n",
      "[n=100 d=4 s=0.6 cs=0.4 ] [-0.8025451  -0.80051913 -0.79723426]\n",
      "[n=100 d=4 s=0.6 cs=0.5 ] [-0.79181022 -0.7869585  -0.78431084]\n",
      "[n=100 d=4 s=0.6 cs=0.6 ] [-0.7873783  -0.77914954 -0.77864174]\n",
      "[n=100 d=4 s=0.6 cs=0.7 ] [-0.78422426 -0.77531281 -0.77437602]\n",
      "[n=100 d=4 s=0.6 cs=0.8 ] [-0.78320407 -0.77279154 -0.77085809]\n",
      "[n=100 d=4 s=0.6 cs=0.9 ] [-0.78229389 -0.77129266 -0.76917791]\n",
      "[n=100 d=4 s=0.6 cs=1.0 ] [-0.7820992  -0.76961978 -0.76871063]\n",
      "[n=100 d=4 s=0.7 cs=0.1 ] [-0.91702575 -0.93817299 -0.94456145]\n",
      "[n=100 d=4 s=0.7 cs=0.2 ] [-0.85162564 -0.85848319 -0.87248356]\n",
      "[n=100 d=4 s=0.7 cs=0.3 ] [-0.81503488 -0.8176477  -0.81750239]\n",
      "[n=100 d=4 s=0.7 cs=0.4 ] [-0.80222866 -0.79948477 -0.79731548]\n",
      "[n=100 d=4 s=0.7 cs=0.5 ] [-0.7922268  -0.78580073 -0.78489089]\n",
      "[n=100 d=4 s=0.7 cs=0.6 ] [-0.78669454 -0.77790185 -0.77848166]\n",
      "[n=100 d=4 s=0.7 cs=0.7 ] [-0.78389617 -0.77456956 -0.77425702]\n",
      "[n=100 d=4 s=0.7 cs=0.8 ] [-0.78268151 -0.77164881 -0.7713792 ]\n",
      "[n=100 d=4 s=0.7 cs=0.9 ] [-0.78139376 -0.77094266 -0.77006065]\n",
      "[n=100 d=4 s=0.7 cs=1.0 ] [-0.78125181 -0.77049215 -0.76905313]\n",
      "[n=100 d=4 s=0.8 cs=0.1 ] [-0.91677217 -0.93780095 -0.94389829]\n",
      "[n=100 d=4 s=0.8 cs=0.2 ] [-0.85108904 -0.85812172 -0.87163078]\n",
      "[n=100 d=4 s=0.8 cs=0.3 ] [-0.81495491 -0.81721245 -0.81786998]\n",
      "[n=100 d=4 s=0.8 cs=0.4 ] [-0.80106348 -0.79927862 -0.79739798]\n",
      "[n=100 d=4 s=0.8 cs=0.5 ] [-0.79105047 -0.78562631 -0.78439141]\n",
      "[n=100 d=4 s=0.8 cs=0.6 ] [-0.78640831 -0.77792313 -0.7783926 ]\n",
      "[n=100 d=4 s=0.8 cs=0.7 ] [-0.78351072 -0.774651   -0.77374329]\n",
      "[n=100 d=4 s=0.8 cs=0.8 ] [-0.78186345 -0.77198809 -0.77192703]\n",
      "[n=100 d=4 s=0.8 cs=0.9 ] [-0.78131593 -0.77132363 -0.77031067]\n",
      "[n=100 d=4 s=0.8 cs=1.0 ] [-0.78126111 -0.77115909 -0.76926761]\n",
      "[n=100 d=4 s=0.9 cs=0.1 ] [-0.91657673 -0.93793955 -0.94444118]\n",
      "[n=100 d=4 s=0.9 cs=0.2 ] [-0.85133625 -0.85771106 -0.87159139]\n",
      "[n=100 d=4 s=0.9 cs=0.3 ] [-0.81422119 -0.81699195 -0.81757632]\n",
      "[n=100 d=4 s=0.9 cs=0.4 ] [-0.80116426 -0.79916011 -0.7970344 ]\n",
      "[n=100 d=4 s=0.9 cs=0.5 ] [-0.79154608 -0.78505274 -0.78405061]\n",
      "[n=100 d=4 s=0.9 cs=0.6 ] [-0.78638801 -0.77775025 -0.77729886]\n",
      "[n=100 d=4 s=0.9 cs=0.7 ] [-0.78398838 -0.77439682 -0.77277646]\n",
      "[n=100 d=4 s=0.9 cs=0.8 ] [-0.78271547 -0.77217355 -0.77097744]\n",
      "[n=100 d=4 s=0.9 cs=0.9 ] [-0.78206165 -0.7715585  -0.77029703]\n",
      "[n=100 d=4 s=0.9 cs=1.0 ] [-0.78184223 -0.77146426 -0.77032794]\n",
      "[n=100 d=4 s=1.0 cs=0.1 ] [-0.94427199 -0.94100468 -0.94122518]\n",
      "[n=100 d=4 s=1.0 cs=0.2 ] [-0.87148547 -0.86481506 -0.86632023]\n",
      "[n=100 d=4 s=1.0 cs=0.3 ] [-0.82210773 -0.8140727  -0.81491343]\n",
      "[n=100 d=4 s=1.0 cs=0.4 ] [-0.80573673 -0.79811833 -0.79826908]\n",
      "[n=100 d=4 s=1.0 cs=0.5 ] [-0.79255115 -0.78525872 -0.78426558]\n",
      "[n=100 d=4 s=1.0 cs=0.6 ] [-0.78810957 -0.77981849 -0.77938286]\n",
      "[n=100 d=4 s=1.0 cs=0.7 ] [-0.78458458 -0.77576994 -0.77493319]\n",
      "[n=100 d=4 s=1.0 cs=0.8 ] [-0.78398426 -0.77307362 -0.77197078]\n",
      "[n=100 d=4 s=1.0 cs=0.9 ] [-0.78308907 -0.77234635 -0.77073008]\n",
      "[n=100 d=4 s=1.0 cs=1.0 ] [-0.7838504  -0.7727598  -0.77096046]\n",
      "[n=100 d=5 s=0.1 cs=0.1 ] [-0.92117449 -0.94382929 -0.9492072 ]\n",
      "[n=100 d=5 s=0.1 cs=0.2 ] [-0.85822021 -0.86530994 -0.87894919]\n",
      "[n=100 d=5 s=0.1 cs=0.3 ] [-0.82240413 -0.82406868 -0.82530782]\n",
      "[n=100 d=5 s=0.1 cs=0.4 ] [-0.81083201 -0.80628049 -0.8043169 ]\n",
      "[n=100 d=5 s=0.1 cs=0.5 ] [-0.80075208 -0.79236583 -0.79229354]\n",
      "[n=100 d=5 s=0.1 cs=0.6 ] [-0.79559375 -0.78646299 -0.78496877]\n",
      "[n=100 d=5 s=0.1 cs=0.7 ] [-0.79211172 -0.78256289 -0.78083129]\n",
      "[n=100 d=5 s=0.1 cs=0.8 ] [-0.79078555 -0.779993   -0.77813235]\n",
      "[n=100 d=5 s=0.1 cs=0.9 ] [-0.78949448 -0.7783244  -0.77427253]\n",
      "[n=100 d=5 s=0.1 cs=1.0 ] [-0.78864929 -0.77589884 -0.77465057]\n",
      "[n=100 d=5 s=0.2 cs=0.1 ] [-0.91530981 -0.93788276 -0.94302349]\n",
      "[n=100 d=5 s=0.2 cs=0.2 ] [-0.85065755 -0.85599838 -0.87036138]\n",
      "[n=100 d=5 s=0.2 cs=0.3 ] [-0.81457118 -0.81675217 -0.81684931]\n",
      "[n=100 d=5 s=0.2 cs=0.4 ] [-0.80095383 -0.79814887 -0.79411283]\n",
      "[n=100 d=5 s=0.2 cs=0.5 ] [-0.78865033 -0.78308076 -0.78150465]\n",
      "[n=100 d=5 s=0.2 cs=0.6 ] [-0.78317384 -0.77577958 -0.77327036]\n",
      "[n=100 d=5 s=0.2 cs=0.7 ] [-0.78098473 -0.77110885 -0.76830542]\n",
      "[n=100 d=5 s=0.2 cs=0.8 ] [-0.77849362 -0.76887627 -0.76455767]\n",
      "[n=100 d=5 s=0.2 cs=0.9 ] [-0.77698317 -0.76693674 -0.76445113]\n",
      "[n=100 d=5 s=0.2 cs=1.0 ] [-0.7760456  -0.76475714 -0.763873  ]\n",
      "[n=100 d=5 s=0.3 cs=0.1 ] [-0.91412371 -0.93514096 -0.94022374]\n",
      "[n=100 d=5 s=0.3 cs=0.2 ] [-0.84667466 -0.85273281 -0.8669263 ]\n",
      "[n=100 d=5 s=0.3 cs=0.3 ] [-0.80960484 -0.81109428 -0.81290305]\n",
      "[n=100 d=5 s=0.3 cs=0.4 ] [-0.79600676 -0.79231993 -0.79112191]\n",
      "[n=100 d=5 s=0.3 cs=0.5 ] [-0.78326282 -0.77901551 -0.77714492]\n",
      "[n=100 d=5 s=0.3 cs=0.6 ] [-0.77824062 -0.7707008  -0.77045985]\n",
      "[n=100 d=5 s=0.3 cs=0.7 ] [-0.77494276 -0.76666053 -0.76519447]\n",
      "[n=100 d=5 s=0.3 cs=0.8 ] [-0.77408239 -0.76334623 -0.76184565]\n",
      "[n=100 d=5 s=0.3 cs=0.9 ] [-0.77291629 -0.76256266 -0.76030864]\n",
      "[n=100 d=5 s=0.3 cs=1.0 ] [-0.77232088 -0.76084727 -0.75861581]\n",
      "[n=100 d=5 s=0.4 cs=0.1 ] [-0.9128173  -0.93407298 -0.9400582 ]\n",
      "[n=100 d=5 s=0.4 cs=0.2 ] [-0.84448787 -0.85114023 -0.86639752]\n",
      "[n=100 d=5 s=0.4 cs=0.3 ] [-0.80702728 -0.80960852 -0.81089495]\n",
      "[n=100 d=5 s=0.4 cs=0.4 ] [-0.79365137 -0.7902212  -0.78914173]\n",
      "[n=100 d=5 s=0.4 cs=0.5 ] [-0.78193632 -0.77547184 -0.77408674]\n",
      "[n=100 d=5 s=0.4 cs=0.6 ] [-0.77646557 -0.76682065 -0.76791644]\n",
      "[n=100 d=5 s=0.4 cs=0.7 ] [-0.77233943 -0.762639   -0.76269179]\n",
      "[n=100 d=5 s=0.4 cs=0.8 ] [-0.77045779 -0.75993585 -0.75997263]\n",
      "[n=100 d=5 s=0.4 cs=0.9 ] [-0.76910165 -0.75809367 -0.75788697]\n",
      "[n=100 d=5 s=0.4 cs=1.0 ] [-0.76865626 -0.75888247 -0.75641608]\n",
      "[n=100 d=5 s=0.5 cs=0.1 ] [-0.91174886 -0.9333813  -0.93923183]\n",
      "[n=100 d=5 s=0.5 cs=0.2 ] [-0.8432004  -0.85048081 -0.86448615]\n",
      "[n=100 d=5 s=0.5 cs=0.3 ] [-0.80443917 -0.80788078 -0.80933305]\n",
      "[n=100 d=5 s=0.5 cs=0.4 ] [-0.79074861 -0.78808291 -0.78663324]\n",
      "[n=100 d=5 s=0.5 cs=0.5 ] [-0.77948405 -0.77304132 -0.77354604]\n",
      "[n=100 d=5 s=0.5 cs=0.6 ] [-0.77403146 -0.76625381 -0.76720489]\n",
      "[n=100 d=5 s=0.5 cs=0.7 ] [-0.77070289 -0.76252254 -0.76068527]\n",
      "[n=100 d=5 s=0.5 cs=0.8 ] [-0.76971077 -0.75924948 -0.75867083]\n",
      "[n=100 d=5 s=0.5 cs=0.9 ] [-0.76838682 -0.75784195 -0.7573087 ]\n",
      "[n=100 d=5 s=0.5 cs=1.0 ] [-0.76779587 -0.75671232 -0.75611519]\n",
      "[n=100 d=5 s=0.6 cs=0.1 ] [-0.91147239 -0.93291354 -0.93850484]\n",
      "[n=100 d=5 s=0.6 cs=0.2 ] [-0.84287514 -0.84957703 -0.86419207]\n",
      "[n=100 d=5 s=0.6 cs=0.3 ] [-0.80339152 -0.80719595 -0.80726377]\n",
      "[n=100 d=5 s=0.6 cs=0.4 ] [-0.78986995 -0.78751989 -0.78583813]\n",
      "[n=100 d=5 s=0.6 cs=0.5 ] [-0.77835923 -0.7731962  -0.77299893]\n",
      "[n=100 d=5 s=0.6 cs=0.6 ] [-0.77224354 -0.76460815 -0.76539494]\n",
      "[n=100 d=5 s=0.6 cs=0.7 ] [-0.76989715 -0.76128174 -0.76003912]\n",
      "[n=100 d=5 s=0.6 cs=0.8 ] [-0.76907576 -0.75897414 -0.7570833 ]\n",
      "[n=100 d=5 s=0.6 cs=0.9 ] [-0.76784283 -0.75748724 -0.75616645]\n",
      "[n=100 d=5 s=0.6 cs=1.0 ] [-0.76773027 -0.75641667 -0.75488447]\n",
      "[n=100 d=5 s=0.7 cs=0.1 ] [-0.91121056 -0.93265823 -0.93828437]\n",
      "[n=100 d=5 s=0.7 cs=0.2 ] [-0.84171473 -0.84881427 -0.8634773 ]\n",
      "[n=100 d=5 s=0.7 cs=0.3 ] [-0.80348642 -0.80650966 -0.80672397]\n",
      "[n=100 d=5 s=0.7 cs=0.4 ] [-0.78954762 -0.78632315 -0.78493322]\n",
      "[n=100 d=5 s=0.7 cs=0.5 ] [-0.77910001 -0.77203067 -0.771798  ]\n",
      "[n=100 d=5 s=0.7 cs=0.6 ] [-0.77203768 -0.76463684 -0.76514796]\n",
      "[n=100 d=5 s=0.7 cs=0.7 ] [-0.76991271 -0.76056038 -0.76021885]\n",
      "[n=100 d=5 s=0.7 cs=0.8 ] [-0.76859843 -0.75741471 -0.75740821]\n",
      "[n=100 d=5 s=0.7 cs=0.9 ] [-0.7673894  -0.75627135 -0.75694482]\n",
      "[n=100 d=5 s=0.7 cs=1.0 ] [-0.767607   -0.75657032 -0.7549774 ]\n",
      "[n=100 d=5 s=0.8 cs=0.1 ] [-0.9112636  -0.93193715 -0.93831724]\n",
      "[n=100 d=5 s=0.8 cs=0.2 ] [-0.84139099 -0.84834006 -0.86254477]\n",
      "[n=100 d=5 s=0.8 cs=0.3 ] [-0.80247218 -0.80517354 -0.80627379]\n",
      "[n=100 d=5 s=0.8 cs=0.4 ] [-0.78791745 -0.78599722 -0.78485507]\n",
      "[n=100 d=5 s=0.8 cs=0.5 ] [-0.77748618 -0.77156758 -0.77131256]\n",
      "[n=100 d=5 s=0.8 cs=0.6 ] [-0.77207126 -0.76393353 -0.76463337]\n",
      "[n=100 d=5 s=0.8 cs=0.7 ] [-0.76932111 -0.7601422  -0.75956088]\n",
      "[n=100 d=5 s=0.8 cs=0.8 ] [-0.76740562 -0.75767058 -0.75712533]\n",
      "[n=100 d=5 s=0.8 cs=0.9 ] [-0.76611498 -0.75618307 -0.75540637]\n",
      "[n=100 d=5 s=0.8 cs=1.0 ] [-0.76637777 -0.75614071 -0.75423326]\n",
      "[n=100 d=5 s=0.9 cs=0.1 ] [-0.91096045 -0.93185272 -0.93802118]\n",
      "[n=100 d=5 s=0.9 cs=0.2 ] [-0.84124199 -0.84724767 -0.86181482]\n",
      "[n=100 d=5 s=0.9 cs=0.3 ] [-0.80158642 -0.80474869 -0.80525361]\n",
      "[n=100 d=5 s=0.9 cs=0.4 ] [-0.78779085 -0.78473149 -0.78426825]\n",
      "[n=100 d=5 s=0.9 cs=0.5 ] [-0.7773356  -0.77151554 -0.77097612]\n",
      "[n=100 d=5 s=0.9 cs=0.6 ] [-0.77181782 -0.76300333 -0.76395445]\n",
      "[n=100 d=5 s=0.9 cs=0.7 ] [-0.76923201 -0.75984069 -0.75884827]\n",
      "[n=100 d=5 s=0.9 cs=0.8 ] [-0.76768647 -0.75783299 -0.75628764]\n",
      "[n=100 d=5 s=0.9 cs=0.9 ] [-0.76781396 -0.75732685 -0.75591111]\n",
      "[n=100 d=5 s=0.9 cs=1.0 ] [-0.76766967 -0.75654707 -0.75593145]\n",
      "[n=100 d=5 s=1.0 cs=0.1 ] [-0.93814847 -0.93403997 -0.93484721]\n",
      "[n=100 d=5 s=1.0 cs=0.2 ] [-0.86159024 -0.85520243 -0.85677606]\n",
      "[n=100 d=5 s=1.0 cs=0.3 ] [-0.80968875 -0.80159043 -0.80333982]\n",
      "[n=100 d=5 s=1.0 cs=0.4 ] [-0.79212981 -0.78497239 -0.78494727]\n",
      "[n=100 d=5 s=1.0 cs=0.5 ] [-0.77830667 -0.77095868 -0.77036336]\n",
      "[n=100 d=5 s=1.0 cs=0.6 ] [-0.77393929 -0.76557063 -0.76498166]\n",
      "[n=100 d=5 s=1.0 cs=0.7 ] [-0.77054248 -0.76167439 -0.76082087]\n",
      "[n=100 d=5 s=1.0 cs=0.8 ] [-0.7688729  -0.75875559 -0.75760177]\n",
      "[n=100 d=5 s=1.0 cs=0.9 ] [-0.76768334 -0.75834317 -0.75702106]\n",
      "[n=100 d=5 s=1.0 cs=1.0 ] [-0.770163   -0.75949082 -0.75820068]\n",
      "[n=100 d=6 s=0.1 cs=0.1 ] [-0.91857879 -0.94097572 -0.94636344]\n",
      "[n=100 d=6 s=0.1 cs=0.2 ] [-0.85434955 -0.86208986 -0.87587487]\n",
      "[n=100 d=6 s=0.1 cs=0.3 ] [-0.81838943 -0.82181731 -0.82019011]\n",
      "[n=100 d=6 s=0.1 cs=0.4 ] [-0.80675262 -0.8027598  -0.80146285]\n",
      "[n=100 d=6 s=0.1 cs=0.5 ] [-0.7954635  -0.78951745 -0.78817334]\n",
      "[n=100 d=6 s=0.1 cs=0.6 ] [-0.78925804 -0.78267475 -0.77973488]\n",
      "[n=100 d=6 s=0.1 cs=0.7 ] [-0.78528462 -0.77776184 -0.77611609]\n",
      "[n=100 d=6 s=0.1 cs=0.8 ] [-0.78676002 -0.77454604 -0.77281695]\n",
      "[n=100 d=6 s=0.1 cs=0.9 ] [-0.78371703 -0.77354267 -0.77037476]\n",
      "[n=100 d=6 s=0.1 cs=1.0 ] [-0.78267779 -0.77121033 -0.77023694]\n",
      "[n=100 d=6 s=0.2 cs=0.1 ] [-0.91262561 -0.93510596 -0.9411003 ]\n",
      "[n=100 d=6 s=0.2 cs=0.2 ] [-0.84643462 -0.85217339 -0.86625145]\n",
      "[n=100 d=6 s=0.2 cs=0.3 ] [-0.80923093 -0.8118903  -0.81095009]\n",
      "[n=100 d=6 s=0.2 cs=0.4 ] [-0.79456614 -0.7921544  -0.78732156]\n",
      "[n=100 d=6 s=0.2 cs=0.5 ] [-0.78133234 -0.77699185 -0.77392999]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-826566e776ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'[n='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' d='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' s='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' cs='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' ] '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    440\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in range(100, 450, 25):\n",
    "    for d in range (2, 12, 1):\n",
    "        for s in np.arange(0.1,1.1,0.1):\n",
    "            for cs in np.arange(0.1,1.1,0.1):\n",
    "                clf = xgb.XGBClassifier(max_depth=d, n_estimators=n, learning_rate=0.05, silent=1, objective='multi:softprob',\n",
    "                        subsample=s,colsample_bytree=cs)\n",
    "                fit = clf.fit(data, target)\n",
    "                proba = fit.predict_proba(test)\n",
    "                print '[n='+str(n)+' d='+str(d)+' s='+str(s)+' cs='+str(cs)+' ] '+str(cross_validation.cross_val_score(clf, data, target, scoring='log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Salvando em arquivo CSV para enviar ao Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-29T15:00:15.121000",
     "start_time": "2016-06-29T15:00:15.072000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#proba = fit.predict_proba(test)\n",
    "ret = pd.DataFrame(proba, index=test.index, columns=fit.classes_)\n",
    "#ret.index = ret.index+1\n",
    "ret.sort_index(inplace=True)\n",
    "ret.to_csv('output/submission.csv', index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.72758765, -0.72300306, -0.71813888])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(clf, data, target, scoring='log_loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[-0.72246914 -0.71717815 -0.7130527 ]\n",
    "\n",
    "[-0.72396381 -0.72211103 -0.71715707]\n",
    "\n",
    "[-0.7252497  -0.72362816 -0.71610143]\n",
    "\n",
    "array([-0.72645001, -0.72301075, -0.71964613])\n",
    "\n",
    "array([-0.72873917, -0.72380463, -0.72159486])\n",
    "\n",
    "array([-0.74041248, -0.73777135, -0.72835238])\n",
    "\n",
    "array([-0.73664086, -0.73223007, -0.72688397]) - 250 todas novas features\n",
    "\n",
    "array([-0.73662436, -0.73447814, -0.72777039]) - 250 novas features com breed (somente size e grupo)\n",
    "\n",
    "array([-0.73897436, -0.73514682, -0.72964329]) - 250 novas features (sem breed)\n",
    "\n",
    "array([-0.74055679, -0.73587788, -0.72771282]) 250\n",
    "\n",
    "array([-0.74086091, -0.73629684, -0.72751988]) 300\n",
    "\n",
    "array([-0.74145022, -0.73730085, -0.72769767]) 325\n",
    "\n",
    "array([-0.73915104, -0.73577702, -0.72817969])\n",
    "\n",
    "array([-0.74346893, -0.73752276, -0.72980024])\n",
    "\n",
    "array([-0.74321041, -0.73832364, -0.73052855])\n",
    "\n",
    "array([-0.74873247, -0.74552813, -0.73572743])\n",
    "\n",
    "array([-0.75646983, -0.74827674, -0.74707565])\n",
    "\n",
    "array([-0.75622374, -0.75086099, -0.74849421])\n",
    "\n",
    "array([-0.75715345, -0.75192073, -0.74662878]) - estimators = 325\n",
    "\n",
    "array([-0.75753229, -0.75203215, -0.74645084]) - estimators = 350\n",
    "\n",
    "array([-0.75726917, -0.75237363, -0.74653154]) - depth = 6\n",
    "\n",
    "array([-0.76324843, -0.75360441, -0.74913675])\n",
    "\n",
    "array([-0.76832682, -0.76022552, -0.75612068])\n",
    "\n",
    "array([-0.77868186, -0.76961524, -0.7654266 ])\n",
    "\n",
    "array([-0.80053641, -0.79496805, -0.79203674])\n",
    "\n",
    "array([-0.87241774, -0.86908006, -0.85758873])\n",
    "\n",
    "array([-0.90137227, -0.89607375, -0.89042396])\n",
    "\n",
    "\n",
    "**Fim** <br />\n",
    "Esse notebook é um exemplo mais simples que podemos fazer o uso do Machine Learning com a bibioteca Python + Sklearn. <br /><br />\n",
    "Existem algumas evolutivas que podem ser feitas para uma melhor performance:\n",
    "- adicionar novas features\n",
    "- fazer uso cross-validation para fazer testes\n",
    "- fazer o uso de ensembling para melhorar o seu score no final\n",
    "- Testar com diferentes parâmetros no seu método.\n",
    "- Etc...\n",
    "\n",
    "O próximo notebook criarei um exemplo usando o Cross-Validation e criando novas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f617f4cb7512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf = xgb.XGBClassifier(max_depth=6, n_estimators=325, learning_rate=0.05, silent=1, objective='multi:softprob',\n\u001b[1;32m      2\u001b[0m                         subsample=0.55,colsample_bytree=0.65)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    440\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcos/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=6, n_estimators=325, learning_rate=0.05, silent=1, objective='multi:softprob',\n",
    "                        subsample=0.55,colsample_bytree=0.65)\n",
    "fit = clf.fit(data, target)\n",
    "proba = fit.predict_proba(test)\n",
    "cross_validation.cross_val_score(clf, data, target, scoring='log_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "fit = clf.fit(data, target)\n",
    "proba = fit.predict_proba(test)\n",
    "cross_validation.cross_val_score(clf, data, target, scoring='log_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret = pd.DataFrame(proba, index=test.index, columns=fit.classes_)\n",
    "ret.sort_index(inplace=True)\n",
    "ret.to_csv('output/submission.csv', index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
